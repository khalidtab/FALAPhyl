distance = merge(distance,sampleIDtable, by.x=c("v1"), by.y=c("v1"))
colnames(sampleIDtable) = c("v2","v2subjectID")
distance = merge(distance,sampleIDtable, by.x=c("v2"), by.y=c("v2"))
# Subset to only those from the same patient
distance = distance[distance$v1subjectID==distance$v2subjectID, ]
colnames(distance) = c("v2","v1",dist_type,"repl","noRepl","cond1","cond2","v1subjectID","v2subjectID")
uniqueCond = c(distance$cond1, distance$cond2) %>% unique(.)
comboUniq = combn(uniqueCond,2,simplify = FALSE)
for (myConds in comboUniq) {
myCond1 = myConds[1]
myCond2 = myConds[2]
table1 = subset(distance,cond1 == myCond1)
table1 = data.frame(table1$v1,table1$v2,table1[,3],table1$repl,table1$noRepl,table1$cond1,table1$cond2) # Rearrange the columns
colnames(table1) = c("v1","v2",dist_type,"repl","noRepl","cond1","cond2") # Fix the names of the columns
table2 = subset(distance,cond2 == myCond1)
colnames(table2) = c("v1","v2",dist_type,"repl","noRepl","cond2","cond1") # This makes table2 to have the same format as table1
table2 = data.frame(table2$v1,table2$v2,table2[,3],table2$repl,table2$noRepl,table2$cond1,table2$cond2) # Rearrange the columns
colnames(table2) = c("v1","v2",dist_type,"repl","noRepl","cond1","cond2") # Fix the names
myTable = rbind(table1,table2)
# By now myTable cond1 equals myCond1. Next, subset mytable so that cond2 equals myCond2
myTable = subset(myTable,cond2 == myCond2)
i = c(3,4,5)
myTable[,i] = apply(myTable[,i],2, function(x) as.numeric(as.character(x)))
rm(table1,table2)
effectSize = rank_biserial(myTable$repl,myTable$noRepl, paired = TRUE) %>% interpret(., rules = "funder2019")
pvalue = wilcox.test(myTable$repl,myTable$noRepl, paired = TRUE) %>% .$p.value
pd = data.frame(replacement = myTable$repl, noreplacement = myTable$noRepl)
numOfParticipants = dim(pd)[1]
if (dist_type == "bray"){
colnames(pd) = c("balanced variation in abundance","abundance gradients")
myGraph = ggpubr::ggpaired(pd, cond1 = "balanced variation in abundance", cond2 = "abundance gradients", fill = "condition", palette = "jco", line.size=0.01,
title= (paste(dist_type, "breakdown \n",myCond1,"and",myCond2, "\n Pvalue <",formatC(pvalue, format = "e", digits = 2))),
subtitle = paste0("n =",numOfParticipants,
". Wilcoxon signed rank sum test, P-value < ", formatC(pvalue, format = "e", digits = 5)),
". Rank biserial effect size= ",formatC(effectSize$r_rank_biserial, format = "g", digits = 2)
)} else {
colnames(pd) = c("Turn-over","Nestedness")
myGraph = ggpubr::ggpaired(pd, cond1 = "Turn-over", cond2 = "Nestedness", fill = "condition", palette = "jco", line.size=0.01,
title= (paste(dist_type, "breakdown\n",myCond1,"and",myCond2)),
subtitle = paste0("n =",numOfParticipants,
"\nWilcoxon signed rank sum test, P-value < ",formatC(pvalue, format = "e", digits = 5),
". Rank biserial effect size= ",formatC(effectSize$r_rank_biserial, format = "g", digits = 2))
)}
ggsave(filename=paste0(output,"/",myCond1,"_",myCond2,".svg"),plot=myGraph)
}
comboUniq
uniqueCond = c(distance$cond1, distance$cond2) %>% unique(.)
uniqueCond
View(distance)
dist_type
dist_type = opt$distance
dist_type
opt$distance = "jaccard"
colnames(distance) = c("v2","v1",dist_type,"repl","noRepl","cond1","cond2","v1subjectID","v2subjectID")
dist_type
dist_type = opt$distance
dist_type
colnames(distance) = c("v2","v1",dist_type,"repl","noRepl","cond1","cond2","v1subjectID","v2subjectID")
uniqueCond = c(distance$cond1, distance$cond2) %>% unique(.)
comboUniq = combn(uniqueCond,2,simplify = FALSE)
for (myConds in comboUniq) {
myCond1 = myConds[1]
myCond2 = myConds[2]
table1 = subset(distance,cond1 == myCond1)
table1 = data.frame(table1$v1,table1$v2,table1[,3],table1$repl,table1$noRepl,table1$cond1,table1$cond2) # Rearrange the columns
colnames(table1) = c("v1","v2",dist_type,"repl","noRepl","cond1","cond2") # Fix the names of the columns
table2 = subset(distance,cond2 == myCond1)
colnames(table2) = c("v1","v2",dist_type,"repl","noRepl","cond2","cond1") # This makes table2 to have the same format as table1
table2 = data.frame(table2$v1,table2$v2,table2[,3],table2$repl,table2$noRepl,table2$cond1,table2$cond2) # Rearrange the columns
colnames(table2) = c("v1","v2",dist_type,"repl","noRepl","cond1","cond2") # Fix the names
myTable = rbind(table1,table2)
# By now myTable cond1 equals myCond1. Next, subset mytable so that cond2 equals myCond2
myTable = subset(myTable,cond2 == myCond2)
i = c(3,4,5)
myTable[,i] = apply(myTable[,i],2, function(x) as.numeric(as.character(x)))
rm(table1,table2)
effectSize = rank_biserial(myTable$repl,myTable$noRepl, paired = TRUE) %>% interpret(., rules = "funder2019")
pvalue = wilcox.test(myTable$repl,myTable$noRepl, paired = TRUE) %>% .$p.value
pd = data.frame(replacement = myTable$repl, noreplacement = myTable$noRepl)
numOfParticipants = dim(pd)[1]
if (dist_type == "bray"){
colnames(pd) = c("balanced variation in abundance","abundance gradients")
myGraph = ggpubr::ggpaired(pd, cond1 = "balanced variation in abundance", cond2 = "abundance gradients", fill = "condition", palette = "jco", line.size=0.01,
title= (paste(dist_type, "breakdown \n",myCond1,"and",myCond2, "\n Pvalue <",formatC(pvalue, format = "e", digits = 2))),
subtitle = paste0("n =",numOfParticipants,
". Wilcoxon signed rank sum test, P-value < ", formatC(pvalue, format = "e", digits = 5)),
". Rank biserial effect size= ",formatC(effectSize$r_rank_biserial, format = "g", digits = 2)
)} else {
colnames(pd) = c("Turn-over","Nestedness")
myGraph = ggpubr::ggpaired(pd, cond1 = "Turn-over", cond2 = "Nestedness", fill = "condition", palette = "jco", line.size=0.01,
title= (paste(dist_type, "breakdown\n",myCond1,"and",myCond2)),
subtitle = paste0("n =",numOfParticipants,
"\nWilcoxon signed rank sum test, P-value < ",formatC(pvalue, format = "e", digits = 5),
". Rank biserial effect size= ",formatC(effectSize$r_rank_biserial, format = "g", digits = 2))
)}
ggsave(filename=paste0(output,"/",myCond1,"_",myCond2,".svg"),plot=myGraph)
}
comboUniq
for (myConds in comboUniq) {
myCond1 = myConds[1]
myCond2 = myConds[2]
table1 = subset(distance,cond1 == myCond1)
table1 = data.frame(table1$v1,table1$v2,table1[,3],table1$repl,table1$noRepl,table1$cond1,table1$cond2) # Rearrange the columns
colnames(table1) = c("v1","v2",dist_type,"repl","noRepl","cond1","cond2") # Fix the names of the columns
table2 = subset(distance,cond2 == myCond1)
colnames(table2) = c("v1","v2",dist_type,"repl","noRepl","cond2","cond1") # This makes table2 to have the same format as table1
table2 = data.frame(table2$v1,table2$v2,table2[,3],table2$repl,table2$noRepl,table2$cond1,table2$cond2) # Rearrange the columns
colnames(table2) = c("v1","v2",dist_type,"repl","noRepl","cond1","cond2") # Fix the names
myTable = rbind(table1,table2)
# By now myTable cond1 equals myCond1. Next, subset mytable so that cond2 equals myCond2
myTable = subset(myTable,cond2 == myCond2)
i = c(3,4,5)
myTable[,i] = apply(myTable[,i],2, function(x) as.numeric(as.character(x)))
rm(table1,table2)
effectSize = rank_biserial(myTable$repl,myTable$noRepl, paired = TRUE) %>% interpret(., rules = "funder2019")
pvalue = wilcox.test(myTable$repl,myTable$noRepl, paired = TRUE) %>% .$p.value
pd = data.frame(replacement = myTable$repl, noreplacement = myTable$noRepl)
numOfParticipants = dim(pd)[1]
if (dist_type == "bray"){
colnames(pd) = c("balanced variation in abundance","abundance gradients")
myGraph = ggpubr::ggpaired(pd, cond1 = "balanced variation in abundance", cond2 = "abundance gradients", fill = "condition", palette = "jco", line.size=0.01,
title= (paste(dist_type, "breakdown \n",myCond1,"and",myCond2, "\n Pvalue <",formatC(pvalue, format = "e", digits = 2))),
subtitle = paste0("n =",numOfParticipants,
". Wilcoxon signed rank sum test, P-value < ", formatC(pvalue, format = "e", digits = 5)),
". Rank biserial effect size= ",formatC(effectSize$r_rank_biserial, format = "g", digits = 2)
)} else {
colnames(pd) = c("Turn-over","Nestedness")
myGraph = ggpubr::ggpaired(pd, cond1 = "Turn-over", cond2 = "Nestedness", fill = "condition", palette = "jco", line.size=0.01,
title= (paste(dist_type, "breakdown\n",myCond1,"and",myCond2)),
subtitle = paste0("n =",numOfParticipants,
"\nWilcoxon signed rank sum test, P-value < ",formatC(pvalue, format = "e", digits = 5),
". Rank biserial effect size= ",formatC(effectSize$r_rank_biserial, format = "g", digits = 2))
)}
ggsave(filename=paste0(output,"/",myCond1,"_",myCond2,".svg"),plot=myGraph)
}
?wilcox.test()
for (myConds in comboUniq) {
myCond1 = myConds[1]
myCond2 = myConds[2]
table1 = subset(distance,cond1 == myCond1)
table1 = data.frame(table1$v1,table1$v2,table1[,3],table1$repl,table1$noRepl,table1$cond1,table1$cond2) # Rearrange the columns
colnames(table1) = c("v1","v2",dist_type,"repl","noRepl","cond1","cond2") # Fix the names of the columns
table2 = subset(distance,cond2 == myCond1)
colnames(table2) = c("v1","v2",dist_type,"repl","noRepl","cond2","cond1") # This makes table2 to have the same format as table1
table2 = data.frame(table2$v1,table2$v2,table2[,3],table2$repl,table2$noRepl,table2$cond1,table2$cond2) # Rearrange the columns
colnames(table2) = c("v1","v2",dist_type,"repl","noRepl","cond1","cond2") # Fix the names
myTable = rbind(table1,table2)
# By now myTable cond1 equals myCond1. Next, subset mytable so that cond2 equals myCond2
myTable = subset(myTable,cond2 == myCond2)
i = c(3,4,5)
myTable[,i] = apply(myTable[,i],2, function(x) as.numeric(as.character(x)))
rm(table1,table2)
effectSize = rank_biserial(myTable$repl,myTable$noRepl, paired = TRUE) %>% interpret(., rules = "funder2019")
pvalue = wilcox.test(myTable$repl,myTable$noRepl, paired = TRUE, exact = FALSE) %>% .$p.value
pd = data.frame(replacement = myTable$repl, noreplacement = myTable$noRepl)
numOfParticipants = dim(pd)[1]
if (dist_type == "bray"){
colnames(pd) = c("balanced variation in abundance","abundance gradients")
myGraph = ggpubr::ggpaired(pd, cond1 = "balanced variation in abundance", cond2 = "abundance gradients", fill = "condition", palette = "jco", line.size=0.01,
title= (paste(dist_type, "breakdown \n",myCond1,"and",myCond2, "\n Pvalue <",formatC(pvalue, format = "e", digits = 2))),
subtitle = paste0("n =",numOfParticipants,
". Wilcoxon signed rank sum test, P-value < ", formatC(pvalue, format = "e", digits = 5)),
". Rank biserial effect size= ",formatC(effectSize$r_rank_biserial, format = "g", digits = 2)
)} else {
colnames(pd) = c("Turn-over","Nestedness")
myGraph = ggpubr::ggpaired(pd, cond1 = "Turn-over", cond2 = "Nestedness", fill = "condition", palette = "jco", line.size=0.01,
title= (paste(dist_type, "breakdown\n",myCond1,"and",myCond2)),
subtitle = paste0("n =",numOfParticipants,
"\nWilcoxon signed rank sum test, P-value < ",formatC(pvalue, format = "e", digits = 5),
". Rank biserial effect size= ",formatC(effectSize$r_rank_biserial, format = "g", digits = 2))
)}
ggsave(filename=paste0(output,"/",myCond1,"_",myCond2,".svg"),plot=myGraph)
}
?rank_biserial
library("DAtest")
library("tidyverse")
?testDA
library("DAtest")
?testDA()
library("DAtest")
?testDA()
library("DAtest")
?testDA
library(DAtest)
?DA.lic()
?testDA
library(DAtest)
?testDA()
?powerDA
library(DAtest)
?DA.lia
library(DAtest)
?DA.tta
?write.csv
library(DAtest)
?testDA()
?powerDA
library(DAtest)
library(tidyverse)
opt = NULL
opt$input = "~/Downloads/annie/diff/v35_oral_gs–condition–minAbd0.001minR5minS2/pairwise/condition–Subgingival_plaque+Supragingival_plaque.tsv"
opt$mapping= "~/Downloads/annie/diff/v35_oral_gs–condition–minAbd0.001minR5minS2/pairwise/condition–Subgingival_plaque+Supragingival_plaque.txt"
df = opt$input
df = read_tsv(df)
dfRows = as.data.frame(df[,1])
df = as.data.frame(df)
rownames(df) = dfRows[,1]
df[,1] = NULL
df[] = lapply(df, as.numeric)
df = t(df)
map = opt$mapping
map = read.csv(map,sep="\t") %>% as.data.frame(.)
opt$category = "condition"
category = opt$category
catNum = which(colnames(map) == category)
working_map = cbind(as.character(map[,1]),
as.character(map[,catNum])) %>% as.data.frame(.)
colnames(working_map) = c("SampleID","condition")
vec = working_map$condition %>% as.factor(.)
opt$thetest = "abc"
mymethod = opt$thetest
final=testDA(df, predictor = vec,tests=c("kru","abc"),cores=1)
df
vec
final=testDA(df, predictor = vec,tests=c("kru","aov"),cores=1)
View(df)
df = preDA(df, min.samples = as.numeric(2), min.reads = as.numeric(5), min.abundance =  as.numeric(0.001))
View(df)
View(df)
final=testDA(df, predictor = vec,tests=c("kru","abc"),cores=1)
library("ANCOM-BC")
final=testDA(df, predictor = vec,tests=c("kru","ttt"),cores=1)
final
df
final=testDA(df, predictor = vec,tests=c("kru","abc"),cores=1)
final=testDA(df, predictor = vec,tests=c("kru","adx"),cores=1)
final=testDA(df, predictor = vec,tests=c("kru","aov"),cores=1)
final=testDA(df, predictor = vec,tests=c("kru","lao"),cores=1)
final=testDA(df, predictor = vec,tests=c("kru","lao2"),cores=1)
final=testDA(df, predictor = vec,tests=c("kru","bay"),cores=1)
final=testDA(df, predictor = vec,tests=c("kru","pea"),cores=1)
final=testDA(df, predictor = vec,tests=c("kru","spe"),cores=1)
final=testDA(df, predictor = vec,tests=c("kru","ds2x"),cores=1)
final=testDA(df, predictor = vec,tests=c("kru","ds2"),cores=1)
testDA(df, predictor = vec,tests=c("ere","ds2"),cores=1)
final=testDA(df, predictor = vec,tests=c("kru","ere"),cores=1)
final=testDA(df, predictor = vec,tests=c("kru","ere2"),cores=1)
final=testDA(df, predictor = vec,tests=c("kru","erq"),cores=1)
final=testDA(df, predictor = vec,tests=c("kru","erq2"),cores=1)
final=testDA(df, predictor = vec,tests=c("kru","fri"),cores=1)
vec
final=testDA(df, predictor = vec,tests=c("kru","neb"),cores=1)
final$table
final=testDA(df, predictor = vec,tests=c("kru","lia"),cores=1)
final=testDA(df, predictor = vec,tests=c("kru","tta"),cores=1)
final
opt$input = "~/Downloads/annie/diff/v35_oral_gs–condition–minAbd0.001minR5minS2/"
opt = NULL
opt$input = "~/Downloads/annie/diff/v35_oral_gs–condition–minAbd0.001minR5minS2/"
myFiles = list.files(path=opt$input,pattern="AUCFDRPower–")
for (myFile in myFiles){
myReadFile = suppressMessages(read_tsv(paste0(opt$input,myFile)))
readFiles = rbind(hi,readFiles)
}
myFiles
?split()
split(myFiles,sep="–")
split(as.data.frame(myFiles),sep="–")
substring()
?substring()
?strsplit()
strsplit(myFiles,split="–")
strsplit(myFiles,split="–") %>% as.data.frame(.)
suppressMessages(library("dplyr"))
suppressMessages(library("tidyverse"))
suppressMessages(library("ggplot2"))
suppressMessages(library("ggpubr"))
strsplit(myFiles,split="–") %>% as.data.frame(.)
strsplit(myFiles,split="–") %>% as.data.frame(.) %>% View(.)
strsplit(myFiles,split="–") %>% as.data.frame(.) %>% .[3,]
strsplit(myFiles,split="–") %>% as.data.frame(.) %>% .[3,] %>% unique(.)
strsplit(myFiles,split="–") %>% as.data.frame(.) %>% .[3,] %>% as.character(.) %>% unique(.)
myFiles = list.files(path=opt$input,pattern="AUCFDRPower–")
myFiles
strsplit(myFiles,split="–") %>% as.data.frame(.) %>% .[3,] %>% as.character(.) %>% unique(.)
strsplit(myFiles,split="–") %>% as.data.frame(.)
View(strsplit(myFiles,split="–") %>% as.data.frame(.))
readFiles = data.frame(matrix(ncol = 6, nrow = 0))
for (myFile in myFiles){
myReadFile = suppressMessages(read_tsv(paste0(opt$input,myFile)))
readFiles = rbind(hi,readFiles)
}
readFiles = data.frame(matrix(ncol = 6, nrow = 0))
for (myFile in myFiles){
myReadFile = suppressMessages(read_tsv(paste0(opt$input,myFile)))
readFiles = rbind(myReadFile,readFiles)
}
View(readFiles)
myReadFile = readFiles %>%
mutate(score = (AUC - 0.5) * Power - FDR)
View(myReadFile)
myAUC = ggerrorplot(myReadFile, x = "Method", y = "AUC",
desc_stat = "mean", color = "Method"
, size=1,add = "jitter") + theme(axis.text.x = element_text(angle=90)) + labs(x="Method", y = "AUC") +
geom_hline(yintercept=0.5,color="red") + rremove("legend")
myPower = ggerrorplot(myReadFile, x = "Method", y = "Power",
desc_stat = "mean", color = "Method"
, size=1,add = "jitter") + theme(axis.text.x = element_text(angle=90)) + labs(x="Method", y = "Power")+ rremove("legend")
myFDR = ggerrorplot(myReadFile, x = "Method", y = "FDR",
desc_stat = "mean", color = "Method"
, size=1,add = "jitter") + theme(axis.text.x = element_text(angle=90)) + labs(x="Method", y = "False Discovery Rate", caption="Higher AUC means spiked features have been identified,\nand AUC=0.5 means spiked features are randomly spread with non-spiked.\nTherefore, we want an AUC as high as possible.\nThat is, spiked features should have low p-values (ie they have been identified).\nPower is the proportion of spiked features that are significant after multiple p-value corrections\nIt is therefore the proportion of features you would expect to detect in a regular analysis.\nThe higher the power, the better.\nFDR indicates the proportion of significant features (after multiple correction)\nthat were not spiked and therefore shouldn't be significant.\nThis should be as low as possible.")+ rremove("legend")
myScores = ggerrorplot(myReadFile, x = "Method", y = "score",
desc_stat = "mean", color = "Method"
, size=1,add = "jitter") + theme(axis.text.x = element_text(angle=90)) + labs(x="Method", y = "Score", title=
"Score", caption="Score is calculated for each method as follows: (Area Under the ROC Curve - 0.5) * Power - False Discovery Rate.\nThe higher the Score, the better the method is estimated to be.")+ rremove("legend")
figure = ggarrange(myAUC, myPower, myFDR,myScores, ncol = 1, nrow = 4)
figure
myScores
myScores = ggerrorplot(myReadFile, x = "Method", y = "score",
desc_stat = "mean", color = "Method"
, size=1,add = "jitter") + geom_hline(yintercept=0.05,color="red") + theme(axis.text.x = element_text(angle=90)) + labs(x="Method", y = "Score", title=
"Score", caption="Score is calculated for each method as follows: (Area Under the ROC Curve - 0.5) * Power - False Discovery Rate.\nThe higher the Score, the better the method is estimated to be.")+ rremove("legend")
myScores
myFiles = list.files(path=opt$input,pattern="AUCFDRPower–")
myFiles
CurrentCategories = strsplit(myFiles,"–")
CurrentCategories = strsplit(myFiles,"–") %>% as.data.frame(.)
View(CurrentCategories)
CurrentCategories = strsplit(myFiles,"–") %>% as.data.frame(.) %>% .[3,] %>% unique(.)
View(CurrentCategories)
CurrentCategories = strsplit(myFiles,"–") %>% as.data.frame(.) %>% .[3,] %>% as.character(.) %>% unique(.)
length(CurrentCategories)
CurrentCategories
?%contains
?contains
?which
myFiles
?str_subset()
str_subset(myFiles,"Subgingival_plaque+Saliva")
str_subset(myFiles,"Subgingival_plaque+Saliva")
str_subset(myFiles,"Subgingival_plaque")
myFiles = list.files(path=opt$input,pattern="AUCFDRPower–")
myFiles
CurrentCategories = strsplit(myFiles,"–") %>% as.data.frame(.) %>% .[3,] %>% as.character(.) %>% unique(.)
CurrentCategories
str_subset(myFiles,"Subgingival_plaque!Saliva")
currentCategory = CurrentCategories[1]
currentCategory
str_subset(currentFiles, currentCategory)
currentFiles
str_subset(myFiles,"Subgingival_plaque!Saliva")
str_subset(myFiles,currentCategory)
currentFiles = str_subset(myFiles,currentCategory)
for (myFile in currentFiles){
myReadFile = suppressMessages(read_tsv(paste0(opt$input,myFile)))
readFiles = rbind(myReadFile,readFiles)
}
View(readFiles)
currentFiles
currentFiles
readFiles = data.frame(matrix(ncol = 6, nrow = 0))
currentFiles = str_subset(myFiles,currentCategory)
for (myFile in currentFiles){
myReadFile = suppressMessages(read_tsv(paste0(opt$input,myFile)))
readFiles = rbind(myReadFile,readFiles)
}
myReadFile = readFiles %>%
mutate(score = (AUC - 0.5) * Power - FDR)
write_tsv(myReadFile,opt$output)
myAUC = ggerrorplot(myReadFile, x = "Method", y = "AUC",
desc_stat = "mean", color = "Method"
, size=1,add = "jitter") + theme(axis.text.x = element_text(angle=90)) + labs(x="Method", y = "AUC") +
geom_hline(yintercept=0.5,color="red") + rremove("legend")
myPower = ggerrorplot(myReadFile, x = "Method", y = "Power",
desc_stat = "mean", color = "Method"
, size=1,add = "jitter") + theme(axis.text.x = element_text(angle=90)) + labs(x="Method", y = "Power")+ rremove("legend")
myFDR = ggerrorplot(myReadFile, x = "Method", y = "FDR",
desc_stat = "mean", color = "Method"
, size=1,add = "jitter") + theme(axis.text.x = element_text(angle=90)) + labs(x="Method", y = "False Discovery Rate", caption="Higher AUC means spiked features have been identified,\nand AUC=0.5 means spiked features are randomly spread with non-spiked.\nTherefore, we want an AUC as high as possible.\nThat is, spiked features should have low p-values (ie they have been identified).\nPower is the proportion of spiked features that are significant after multiple p-value corrections\nIt is therefore the proportion of features you would expect to detect in a regular analysis.\nThe higher the power, the better.\nFDR indicates the proportion of significant features (after multiple correction)\nthat were not spiked and therefore shouldn't be significant.\nThis should be as low as possible.")+ rremove("legend")
myScores = ggerrorplot(myReadFile, x = "Method", y = "score",
desc_stat = "mean", color = "Method"
, size=1,add = "jitter") + geom_hline(yintercept=0.05,color="red") + theme(axis.text.x = element_text(angle=90)) + labs(x="Method", y = "Score", title=
"Score", caption="Score is calculated for each method as follows: (Area Under the ROC Curve - 0.5) * Power - False Discovery Rate.\nThe higher the Score, the better the method is estimated to be.")+ rremove("legend")
figure = ggarrange(myAUC, myPower, myFDR,myScores, ncol = 1, nrow = 4)
figure
currentCategory
opt$input
myFiles = list.files(path=opt$input,pattern="AUCFDRPower–")
myFIles
myFiles
CurrentCategories = strsplit(myFiles,"–") %>% as.data.frame(.)
currentCategories
CurrentCategories
View(CurrentCategories)
CurrentCategories = strsplit(myFiles,"–") %>% as.data.frame(.) %>% .[3,] %>% as.character(.) %>% unique(.)
CurrentCategories
currentCategory[1]
currentCategory
readFiles = data.frame(matrix(ncol = 6, nrow = 0))
readFiles
currentFiles = str_subset(myFiles,currentCategory)
currentFiles
for (myFile in currentFiles){
myReadFile = suppressMessages(read_tsv(paste0(opt$input,myFile)))
readFiles = rbind(myReadFile,readFiles)
}
myReadFile = readFiles %>%
mutate(score = (AUC - 0.5) * Power - FDR)
View(myReadFile)
opt$output
currentCategory
write_tsv(myReadFile,
paste0(opt$input,"PowerScores–",currentCategory))
myAUC = ggerrorplot(myReadFile, x = "Method", y = "AUC",
desc_stat = "mean", color = "Method"
, size=1,add = "jitter") + theme(axis.text.x = element_text(angle=90)) + labs(x="Method", y = "AUC") +
geom_hline(yintercept=0.5,color="red") + rremove("legend")
myPower = ggerrorplot(myReadFile, x = "Method", y = "Power",
desc_stat = "mean", color = "Method"
, size=1,add = "jitter") + theme(axis.text.x = element_text(angle=90)) + labs(x="Method", y = "Power")+ rremove("legend")
myFDR = ggerrorplot(myReadFile, x = "Method", y = "FDR",
desc_stat = "mean", color = "Method"
, size=1,add = "jitter") + theme(axis.text.x = element_text(angle=90)) + labs(x="Method", y = "False Discovery Rate", caption="Higher AUC means spiked features have been identified,\nand AUC=0.5 means spiked features are randomly spread with non-spiked.\nTherefore, we want an AUC as high as possible.\nThat is, spiked features should have low p-values (ie they have been identified).\nPower is the proportion of spiked features that are significant after multiple p-value corrections\nIt is therefore the proportion of features you would expect to detect in a regular analysis.\nThe higher the power, the better.\nFDR indicates the proportion of significant features (after multiple correction)\nthat were not spiked and therefore shouldn't be significant.\nThis should be as low as possible.")+ rremove("legend")
myScores = ggerrorplot(myReadFile, x = "Method", y = "score",
desc_stat = "mean", color = "Method"
, size=1,add = "jitter") + geom_hline(yintercept=0.05,color="red") + theme(axis.text.x = element_text(angle=90)) + labs(x="Method", y = "Score", title=
"Score", caption="Score is calculated for each method as follows: (Area Under the ROC Curve - 0.5) * Power - False Discovery Rate.\nThe higher the Score, the better the method is estimated to be.")+ rremove("legend")
figure = ggarrange(myAUC, myPower, myFDR,myScores, ncol = 1, nrow = 4)
currentCategory
for (currentCategory in CurrentCategories){
readFiles = data.frame(matrix(ncol = 6, nrow = 0))
currentFiles = str_subset(myFiles,currentCategory)
for (myFile in currentFiles){
myReadFile = suppressMessages(read_tsv(paste0(opt$input,myFile)))
readFiles = rbind(myReadFile,readFiles)
}
myReadFile = readFiles %>%
mutate(score = (AUC - 0.5) * Power - FDR)
write_tsv(myReadFile,
paste0(opt$input,"PowerScores–",currentCategory))
myAUC = ggerrorplot(myReadFile, x = "Method", y = "AUC",
desc_stat = "mean", color = "Method"
, size=1,add = "jitter") + theme(axis.text.x = element_text(angle=90)) + labs(x="Method", y = "AUC") +
geom_hline(yintercept=0.5,color="red") + rremove("legend")
myPower = ggerrorplot(myReadFile, x = "Method", y = "Power",
desc_stat = "mean", color = "Method"
, size=1,add = "jitter") + theme(axis.text.x = element_text(angle=90)) + labs(x="Method", y = "Power")+ rremove("legend")
myFDR = ggerrorplot(myReadFile, x = "Method", y = "FDR",
desc_stat = "mean", color = "Method"
, size=1,add = "jitter") + theme(axis.text.x = element_text(angle=90)) + labs(x="Method", y = "False Discovery Rate", caption="Higher AUC means spiked features have been identified,\nand AUC=0.5 means spiked features are randomly spread with non-spiked.\nTherefore, we want an AUC as high as possible.\nThat is, spiked features should have low p-values (ie they have been identified).\nPower is the proportion of spiked features that are significant after multiple p-value corrections\nIt is therefore the proportion of features you would expect to detect in a regular analysis.\nThe higher the power, the better.\nFDR indicates the proportion of significant features (after multiple correction)\nthat were not spiked and therefore shouldn't be significant.\nThis should be as low as possible.")+ rremove("legend")
myScores = ggerrorplot(myReadFile, x = "Method", y = "score",
desc_stat = "mean", color = "Method"
, size=1,add = "jitter") + geom_hline(yintercept=0.05,color="red") + theme(axis.text.x = element_text(angle=90)) + labs(x="Method", y = "Score", title=
"Score", caption="Score is calculated for each method as follows: (Area Under the ROC Curve - 0.5) * Power - False Discovery Rate.\nThe higher the Score, the better the method is estimated to be.")+ rremove("legend")
figure = ggarrange(myAUC, myPower, myFDR,myScores, ncol = 1, nrow = 4)
#svg(paste0("/data/diff/DAtest–",currentCategory),width = 10, height = 20)
#figure
#dev.off()
}
suppressWarnings(suppressMessages(library(tidyverse)))
suppressWarnings(suppressMessages(library(dunn.test)))
suppressWarnings(suppressMessages(library(magrittr)))
opt = NULL
opt$input =
""
opt$input = "~/Downloads/annie/diff/v35_oral_gs–condition–minAbd0.001minR5minS2/"
myFiles = list.files(path=opt$input,pattern="PowerScores–")
myFiles
myFiles = list.files(path=opt$input,pattern="AUCFDRPower–")
CurrentCategories = strsplit(myFiles,"–") %>% as.data.frame(.) %>% .[3,] %>% as.character(.) %>% unique(.)
cirrentCategories
CurrentCategories
myFiles
CurrentCategories = strsplit(myFiles,"–") %>% as.data.frame(.) %>% .[2,] %>% as.character(.) %>% unique(.)
currentCategories
CurrentCategories
myFiles = list.files(path=opt$input,pattern="PowerScores–")
CurrentCategories = strsplit(myFiles,"–") %>% as.data.frame(.) %>% .[2,] %>% as.character(.) %>% unique(.)
CurrentCategories
paste0(opt$input,currentCategory)
currentCategory
currentCategory = CurrentCategories[1]
paste0(opt$input,currentCategory)
currentCategory = myFiles[1]
currentCategory
myFile = read_tsv(paste0(opt$input,currentCategory))
View(myFile)
myResults = dunn.test(myFile$score,myFile$Method,method="bh") %>% as.data.frame(.)
myResults
currentCategory
paste0(opt$output,"Dunns–",currentCategory)
for (currentCategory in myFiles){
myFile = read_tsv(paste0(opt$input,currentCategory))
myResults = dunn.test(myFile$score,myFile$Method,method="bh") %>% as.data.frame(.)
write_tsv(myResults,paste0(opt$output,"Dunns–",currentCategory))
}
opt$output
for (currentCategory in myFiles){
myFile = read_tsv(paste0(opt$input,currentCategory))
myResults = dunn.test(myFile$score,myFile$Method,method="bh") %>% as.data.frame(.)
write_tsv(myResults,paste0(opt$input,"Dunns–",currentCategory))
}
suppressMessages(library("dplyr"))
suppressMessages(library("tidyverse"))
suppressMessages(library("ggplot2"))
suppressMessages(library("ggpubr"))
suppressMessages(library("dplyr"))
suppressMessages(library("tidyverse"))
suppressMessages(library("ggplot2"))
suppressMessages(library("ggpubr"))
opt = NULL
opt$input = "data/diff/v35_oral_gs–condition–minAbd0.001minR5minS2/Subgingival_plaque!Supragingival_plaque/AUC_FDR_Power"
