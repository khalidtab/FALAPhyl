# Global means per method, to be nudged right
global_meansAUC <- theTestFiles %>%
group_by(Method, Method_numeric) %>%
summarise(GlobalMean = mean(AUC, na.rm = TRUE), .groups = "drop") %>%
mutate(Method_nudged = Method_numeric + 0.4)
# Effect-size-specific means per method & comparison, to be nudged + jittered
effect_meansAUC <- theTestFiles %>%
group_by(comparison, Method, Method_numeric, effect_size_factor) %>%
summarise(EffectMean = mean(AUC, na.rm = TRUE), .groups = "drop") %>%
mutate(Method_nudged = Method_numeric + 0.4)
# Plot
AUC <- ggplot(theTestFiles, aes(x = Method_numeric, y = AUC)) +
# Raw AUC points
geom_jitter(aes(alpha = effect_size_factor), color = "black", width = 0.2, size = 1) +
# Effect size means: white circles, nudged + jittered horizontally
geom_point(data = effect_meansAUC,
aes(x = Method_nudged, y = EffectMean, alpha = effect_size_factor),
inherit.aes = FALSE,
shape = 21, fill = "blue", color = "black", size = 5,
position = position_jitter(width = 0.1, height = 0)) +
# Global means: black triangle, nudged right (no jitter)
geom_point(data = global_meansAUC,
aes(x = Method_nudged, y = GlobalMean),
inherit.aes = FALSE,
shape = 24, fill = "black", color = "white", size = 3) +
# Reference line at AUC = 0.5
geom_hline(yintercept = 0.5, linetype = "dashed", color = "red") +
# Facet per comparison
facet_wrap(~ comparison, ncol = 1, scales = "free_y") +
# Use numeric scale for x, with original method labels
scale_x_continuous(
breaks = method_map$Method_numeric,
labels = method_map$Method
) +
# Labels & styling
labs(
x = "Method",
y = "AUC",
alpha = "Effect Size",
caption = paste(
"• Black dots: individual AUCs (transparency = effect size)",
"• Blue circles: per-effect-size means (transparency = effect size)",
"• Black triangles: global mean across comparisons (nudged)",
"• Dashed red line = AUC = 0.5 = random performance, means spiked features are randomly spread with non-spiked.",
"Therefore, we want an AUC as high as possible. That is, spiked features should have low p-values (ie they have been identified)",
sep = "\n"
)
) +
theme_minimal(base_size = 12) +
theme(
axis.text.x = element_text(angle = 90, hjust = 1),
strip.text = element_text(face = "bold", size = 11),
plot.caption = element_text(size = 9),
legend.position = "right"
)
return(AUC)
}
plotPower = function(){
#### POWER ####
# Ensure effect size is factor for alpha/transparency
theTestFiles <- theTestFiles %>%
mutate(effect_size_factor = as.factor(effect_size))
# Create numeric mapping for Method
method_levels <- unique(theTestFiles$Method)
method_map <- data.frame(Method = method_levels, Method_numeric = 1:length(method_levels))
# Join numeric x-position to data
theTestFiles <- theTestFiles %>%
left_join(method_map, by = "Method")
# Global mean Power per method
global_meansPower <- theTestFiles %>%
group_by(Method, Method_numeric) %>%
summarise(GlobalMean = mean(Power, na.rm = TRUE), .groups = "drop") %>%
mutate(Method_nudged = Method_numeric + 0.4)
# Effect-size-specific mean Power
effect_meansPower <- theTestFiles %>%
group_by(comparison, Method, Method_numeric, effect_size_factor) %>%
summarise(EffectMean = mean(Power, na.rm = TRUE), .groups = "drop") %>%
mutate(Method_nudged = Method_numeric + 0.4)
# Plot
Power <- ggplot(theTestFiles, aes(x = Method_numeric, y = Power)) +
# Raw Power points
geom_jitter(aes(alpha = effect_size_factor), color = "black", width = 0.2, size = 1) +
# Effect size means: green circles, jittered horizontally
geom_point(data = effect_meansPower,
aes(x = Method_nudged, y = EffectMean, alpha = effect_size_factor),
inherit.aes = FALSE,
shape = 21, fill = "darkgreen", color = "black", size = 5,
position = position_jitter(width = 0.1, height = 0)) +
# Global means: black triangle, nudged only
geom_point(data = global_meansPower,
aes(x = Method_nudged, y = GlobalMean),
inherit.aes = FALSE,
shape = 24, fill = "black", color = "white", size = 3) +
# Facet by comparison
facet_wrap(~ comparison, ncol = 1, scales = "free_y") +
# Numeric x-axis with original method names
scale_x_continuous(
breaks = method_map$Method_numeric,
labels = method_map$Method
) +
# Labels & caption
labs(
x = "Method",
y = "Power",
alpha = "Effect Size",
caption = paste(
"• Black dots: individual Power values (transparency = effect size)",
"• Green circles: per-effect-size means (jittered + nudged)",
"• Black triangles: global mean across all comparisons (nudged)",
"• Power is the proportion of spiked features that are significant after multiple p-value corrections.",
"The higher the power, the better.",
sep = "\n"
)
) +
theme_minimal(base_size = 12) +
theme(
axis.text.x = element_text(angle = 90, hjust = 1),
strip.text = element_text(face = "bold", size = 11),
plot.caption = element_text(size = 9),
legend.position = "right"
)
return(Power)
}
plotFDR = function(){
#### FDR ####
# Ensure effect size is a factor for alpha/transparency
theTestFiles <- theTestFiles %>%
mutate(effect_size_factor = as.factor(effect_size))
# Numeric x-axis for method
method_levels <- unique(theTestFiles$Method)
method_map <- data.frame(Method = method_levels, Method_numeric = 1:length(method_levels))
theTestFiles <- theTestFiles %>%
left_join(method_map, by = "Method")
# Global FDR means per method
global_meansFDR <- theTestFiles %>%
group_by(Method, Method_numeric) %>%
summarise(GlobalMean = mean(FDR, na.rm = TRUE), .groups = "drop") %>%
mutate(Method_nudged = Method_numeric + 0.4)
# Effect-size-specific FDR means
effect_meansFDR <- theTestFiles %>%
group_by(comparison, Method, Method_numeric, effect_size_factor) %>%
summarise(EffectMean = mean(FDR, na.rm = TRUE), .groups = "drop") %>%
mutate(Method_nudged = Method_numeric + 0.4)
# Plot
FDR <- ggplot(theTestFiles, aes(x = Method_numeric, y = FDR)) +
# Jittered individual FDR points
geom_jitter(aes(alpha = effect_size_factor), color = "black", width = 0.2, size = 1) +
# Effect size means: white circles, jittered horizontally
geom_point(data = effect_meansFDR,
aes(x = Method_nudged, y = EffectMean, alpha = effect_size_factor),
inherit.aes = FALSE,
shape = 21, fill = "maroon", color = "black", size = 5,
position = position_jitter(width = 0.1, height = 0)) +
# Global means: black triangle, nudged right
geom_point(data = global_meansFDR,
aes(x = Method_nudged, y = GlobalMean),
inherit.aes = FALSE,
shape = 24, fill = "black", color = "white", size = 3) +
# Facet per comparison
facet_wrap(~ comparison, ncol = 1, scales = "free_y") +
# Method names on x-axis
scale_x_continuous(
breaks = method_map$Method_numeric,
labels = method_map$Method
) +
# Labels and caption
labs(
x = "Method",
y = "False Discovery Rate (FDR)",
alpha = "Effect Size",
caption = paste(
"• Black dots: individual FDR values (transparency = effect size)",
"• Maroon circles: per-effect-size means (jittered + nudged)",
"• Black triangles: global mean across comparisons (nudged)",
"• FDR is the proportion of significant features that were NOT spiked (after multiple comparison adjustment) that were not spiked and therefore shouldn't be significant",
"• Lower is better — high FDR indicates false positives",
sep = "\n"
)
) +
theme_minimal(base_size = 12) +
theme(
axis.text.x = element_text(angle = 90, hjust = 1),
strip.text = element_text(face = "bold", size = 11),
plot.caption = element_text(size = 9),
legend.position = "right"
)
return(FDR)
}
plotScore = function(){
#### SCORE ####
# Ensure effect size is a factor for alpha/transparency
theTestFiles <- theTestFiles %>%
mutate(effect_size_factor = as.factor(effect_size))
# Numeric mapping for Method axis
method_levels <- unique(theTestFiles$Method)
method_map <- data.frame(Method = method_levels, Method_numeric = 1:length(method_levels))
theTestFiles <- theTestFiles %>%
left_join(method_map, by = "Method")
# Global mean scores per method
global_meansScore <- theTestFiles %>%
group_by(Method, Method_numeric) %>%
summarise(GlobalMean = mean(score, na.rm = TRUE), .groups = "drop") %>%
mutate(Method_nudged = Method_numeric + 0.4)
# Per-effect-size mean scores
effect_meansScore <- theTestFiles %>%
group_by(comparison, Method, Method_numeric, effect_size_factor) %>%
summarise(EffectMean = mean(score, na.rm = TRUE), .groups = "drop") %>%
mutate(Method_nudged = Method_numeric + 0.4)
# Plot
Score <- ggplot(theTestFiles, aes(x = Method_numeric, y = score)) +
# Raw score points
geom_jitter(aes(alpha = effect_size_factor), color = "black", width = 0.2, size = 1) +
# Effect size means (blue circles, jittered horizontally)
geom_point(data = effect_meansScore,
aes(x = Method_nudged, y = EffectMean, alpha = effect_size_factor),
inherit.aes = FALSE,
shape = 21, fill = "orange", color = "black", size = 5,
position = position_jitter(width = 0.1, height = 0)) +
# Global mean scores (black triangles, nudged right)
geom_point(data = global_meansScore,
aes(x = Method_nudged, y = GlobalMean),
inherit.aes = FALSE,
shape = 24, fill = "black", color = "white", size = 3) +
# Facet by comparison
facet_wrap(~ comparison, ncol = 1, scales = "free_y") +
# Original Method labels on x-axis
scale_x_continuous(
breaks = method_map$Method_numeric,
labels = method_map$Method
) +
# Labels & styling
labs(
x = "Method",
y = "Score",
title = "Score",
alpha = "Effect Size",
caption = paste(
"• Black dots: individual scores (transparency = effect size)",
"• Orange circles: per-effect-size mean scores (jittered + nudged)",
"• Black triangles: global mean score across comparisons (nudged)",
"• Score = (AUC - 0.5) * Power - FDR",
"• The higher the Score, the better the method is estimated to be",
sep = "\n"
)
) +
theme_minimal(base_size = 12) +
theme(
axis.text.x = element_text(angle = 90, hjust = 1),
strip.text = element_text(face = "bold", size = 11),
plot.caption = element_text(size = 9),
legend.position = "right"
)
return(Score)
}
########################
AUC = plotAUC()
Power = plotPower()
FDR = plotFDR()
Score = plotScore()
AUC = plotAUC()
Power = plotPower()
FDR = plotFDR()
Score = plotScore()
rm(plotAUC,plotPower,plotFDR,plotScore)
gc()
svg("~/Desktop/AUC.svg",width = 10, height = 20)
AUC
dev.off()
library("svglite")
svg(opt$auc,width = 10, height = 20)
AUC
dev.off()
pdf("~/Desktop/AUC.pdf",width = 10, height = 20)
AUC
dev.off()
pdf("~/Desktop/AUC.pdf",width = 10)
AUC
dev.off()
length(comparison)
length(comparisons)
pdf("~/Desktop/auc.pdf",width = 10, height = (10*length(comparisons)))
AUC
dev.off()
pdf("~/Desktop/auc.pdf", height = (10*length(comparisons)))
AUC
dev.off()
pdf("~/Desktop/auc.pdf",width = 10, height = (10*length(comparisons)))
AUC
dev.off()
pdf("~/Desktop/auc.pdf",width = 20, height = (10*length(comparisons)))
AUC
dev.off()
write_tsv(theTestFiles,"/Users/khaled/Desktop/sequencers_part2/HMP/falaphyl/diff/HMP–bodysite–minAbd0.001minR5minS2/AUC_FDR_Power/AUC_FDR_Power.txt")
myFile = theTestFiles
myResults = dunn.test(myFile$score,myFile$Method,method="bh") %>% as.data.frame(.)
myResults = dunn.test(myFile$score,myFile$Method,method="bh") %>% as.data.frame(.)
if (length(unique(myFile$Method)) == 2) {
wilcox.test(score ~ Method, data = myFile)
} else if (length(unique(myFile$Method)) > 2) {
dunn.test(myFile$score, myFile$Method, method = "bh")
} else {
message("Only one group found. No test needed.")
}
if (length(unique(myFile$Method)) == 2) {
myResults = wilcox.test(score ~ Method, data = myFile)
} else if (length(unique(myFile$Method)) > 2) {
myResults = dunn.test(myFile$score, myFile$Method, method = "bh")
} else {
message("Only one group found. No test needed.")
}
myResults = wilcox.test(score ~ Method, data = myFile)
myResults
#!/usr/local/bin/Rscript --vanilla
suppressWarnings(suppressMessages(library(optparse)))
suppressWarnings(suppressMessages(library(tidyverse)))
suppressWarnings(suppressMessages(library(dunn.test)))
suppressWarnings(suppressMessages(library(magrittr)))
opt = NULL
opt$input = "/Users/khaled/Desktop/sequencers_part2/HMP/falaphyl_reduced/diff/HMP_reduced–bodysite–minAbd0.001minR5minS2/AUC_FDR_Power.txt"
myFile = read_tsv(opt$input)
if (length(unique(myFile$Method)) == 2) {
myResults = wilcox.test(score ~ Method, data = myFile)
} else if (length(unique(myFile$Method)) > 2) {
myResults = dunn.test(myFile$score, myFile$Method, method = "bh")
} else {
message("Only one group found. No test needed.")
myResults = as.data.frame("one group")
}
?writeLines()
myResults
myResults2=as.data.frame(myResults)
as.character(myResults)
print(myResults)
View(myFile)
length(unique(myFile$Method)) > 2
length(unique(myFile$Method))
all_comparisons <- unique(myFile$comparison)
results_list <- list()
for (comp in all_comparisons) {
sub_data <- myFile %>% filter(comparison == comp)
n_groups <- length(unique(sub_data$test_type))
if (n_groups < 2) {
message(paste("Skipping:", comp, "— only one group"))
results_list[[comp]] <- data.frame(Comparison = comp, Message = "Only one group")
} else if (n_groups == 2) {
# Wilcoxon test
test_result <- wilcox.test(score ~ test_type, data = sub_data)
results_list[[comp]] <- data.frame(
Comparison = comp,
Method = "Wilcoxon",
p_value = test_result$p.value
)
} else {
# Dunn test
dt <- dunn.test(sub_data$score, sub_data$test_type, method = "bh", kw = FALSE)
df <- data.frame(
Comparison = comp,
ComparisonGroup = dt$comparisons,
Z = dt$Z,
P = dt$P,
P.adjusted = dt$P.adjusted
)
results_list[[comp]] <- df
}
}
all_results <- bind_rows(results_list)
View(all_results)
output <- capture.output(print(all_results))
output
#!/usr/local/bin/Rscript --vanilla
suppressWarnings(suppressMessages(library(optparse)))
suppressWarnings(suppressMessages(library(tidyverse)))
suppressWarnings(suppressMessages(library(dunn.test)))
suppressWarnings(suppressMessages(library(magrittr)))
opt = NULL
opt$mapping = "/Users/khaled/Desktop/sequencers_part2/HMP/falaphyl_reduced/HMP_reduced.txt"
# Functions
load_and_fix_Dis = function(myInput){
myDis = read.csv(myInput,comment="",sep = "\t",row.names = 1)
myDis[lower.tri(myDis)] = NA
myDis[,1] = row.names(myDis)
colnames(myDis)[1] = "X"
myDis = suppressMessages(reshape2::melt(myDis,na.rm = TRUE))
colnames(myDis) = c("SampleID","variable","value")
myDis = myDis[!(myDis$SampleID == myDis$variable),] # Delete distances from self
myDis = left_join(myDis,mymap,by="SampleID")
colnames(myDis) = c("SampleID1","SampleID","value1","condition1")
myDis = left_join(myDis,mymap,by="SampleID")
colnames(myDis) = c("SampleID1","SampleID2","value1","condition1","condition2")
myDis = cbind(myDis$condition1,myDis$condition2,myDis$value1)
colnames(myDis) = c("condition1","condition2","value")
myDis = as.data.frame(myDis)
TorF = myDis$condition1 > myDis$condition2 # Make sure that category 1 and 2 are always in the right order so that we don't, for example, have an issue where the same 2 categories just switched placed in the two columns
myDis = cbind(myDis,TorF)
myDisTRUE = subset(myDis,TorF == "TRUE")
myDisFALSE = subset(myDis,TorF == "FALSE")
myDisFALSE = myDisFALSE %$% data_frame(condition2,condition1,value,TorF)
colnames(myDisFALSE) = c("condition1","condition2","value","TorF")
myDis = rbind(myDisFALSE,myDisTRUE)
myDis = cbind(myDis,paste0(myDis$condition1,"+",myDis$condition2))
colnames(myDis) = c("condition1","condition2","value","TorF","comparison")
myDis = myDis %$% data.frame(comparison,value)
return(myDis)
}
GiveMeDunn = function(myDis){
myDunn = dunn.test(myDis$value %>% as.numeric(.),
myDis$comparison,
method="bh",kw=FALSE,table=FALSE,list=FALSE) %$% data.frame(comparisons,Z,P,P.adjusted)
myDunn[c('Category 1', 'Category 2')] = str_split_fixed(myDunn$comparison, ' - ', 2)
DistanceInCategory1BiggerThanCategory2 = (myDunn$Z > 0)
myDunn = cbind(myDunn,DistanceInCategory1BiggerThanCategory2)
myDunn = myDunn %$% data.frame(`Category 1`,`Category 2`,Z,P,P.adjusted,DistanceInCategory1BiggerThanCategory2)
return(myDunn)
}
# Load and format mapping file
mymap = suppressMessages(read.csv(opt$mapping, skip=0, header=T, sep="\t"))
colnames(mymap)[1] = "SampleID"
opt$category = "bodysite"
catNum = which(colnames(mymap) == opt$category)
mymap = cbind(mymap[,1],mymap[,catNum]) %>% as.data.frame(.)
colnames(mymap) = c("SampleID","condition")
myDis = load_and_fix_Dis(opt$input) # Load dissimilarity matrix, "melt" it, and make sure that category 1 and category 2 do not switch places
opt$input
opt$input = "/Users/khaled/Desktop/sequencers_part2/HMP/falaphyl_reduced/distance/beta_div/HMP_reduced–PhILR.tsv"
catNum = which(colnames(mymap) == opt$category)
mymap = cbind(mymap[,1],mymap[,catNum]) %>% as.data.frame(.)
colnames(mymap) = c("SampleID","condition")
# Functions
load_and_fix_Dis = function(myInput){
myDis = read.csv(myInput,comment="",sep = "\t",row.names = 1)
myDis[lower.tri(myDis)] = NA
myDis[,1] = row.names(myDis)
colnames(myDis)[1] = "X"
myDis = suppressMessages(reshape2::melt(myDis,na.rm = TRUE))
colnames(myDis) = c("SampleID","variable","value")
myDis = myDis[!(myDis$SampleID == myDis$variable),] # Delete distances from self
myDis = left_join(myDis,mymap,by="SampleID")
colnames(myDis) = c("SampleID1","SampleID","value1","condition1")
myDis = left_join(myDis,mymap,by="SampleID")
colnames(myDis) = c("SampleID1","SampleID2","value1","condition1","condition2")
myDis = cbind(myDis$condition1,myDis$condition2,myDis$value1)
colnames(myDis) = c("condition1","condition2","value")
myDis = as.data.frame(myDis)
TorF = myDis$condition1 > myDis$condition2 # Make sure that category 1 and 2 are always in the right order so that we don't, for example, have an issue where the same 2 categories just switched placed in the two columns
myDis = cbind(myDis,TorF)
myDisTRUE = subset(myDis,TorF == "TRUE")
myDisFALSE = subset(myDis,TorF == "FALSE")
myDisFALSE = myDisFALSE %$% data_frame(condition2,condition1,value,TorF)
colnames(myDisFALSE) = c("condition1","condition2","value","TorF")
myDis = rbind(myDisFALSE,myDisTRUE)
myDis = cbind(myDis,paste0(myDis$condition1,"+",myDis$condition2))
colnames(myDis) = c("condition1","condition2","value","TorF","comparison")
myDis = myDis %$% data.frame(comparison,value)
return(myDis)
}
GiveMeDunn = function(myDis){
myDunn = dunn.test(myDis$value %>% as.numeric(.),
myDis$comparison,
method="bh",kw=FALSE,table=FALSE,list=FALSE) %$% data.frame(comparisons,Z,P,P.adjusted)
myDunn[c('Category 1', 'Category 2')] = str_split_fixed(myDunn$comparison, ' - ', 2)
DistanceInCategory1BiggerThanCategory2 = (myDunn$Z > 0)
myDunn = cbind(myDunn,DistanceInCategory1BiggerThanCategory2)
myDunn = myDunn %$% data.frame(`Category 1`,`Category 2`,Z,P,P.adjusted,DistanceInCategory1BiggerThanCategory2)
return(myDunn)
}
# Load and format mapping file
mymap = suppressMessages(read.csv(opt$mapping, skip=0, header=T, sep="\t"))
colnames(mymap)[1] = "SampleID"
catNum = which(colnames(mymap) == opt$category)
mymap = cbind(mymap[,1],mymap[,catNum]) %>% as.data.frame(.)
colnames(mymap) = c("SampleID","condition")
myDis = load_and_fix_Dis(opt$input) # Load dissimilarity matrix, "melt" it, and make sure that category 1 and category 2 do not switch places
myStats = myDis%>% group_by(comparison)%>% summarise(Median=median(as.numeric(value)), Max=max(as.numeric(value)), Min=min(as.numeric(value)), IQR=IQR(as.numeric(value)))
View(myStats)
myKruskall =  myDis %$% kruskal.test(value,comparison)
myKruskall
myDunn = GiveMeDunn(myDis)
myDunn
#!/usr/local/bin/Rscript --vanilla
set.seed(1234)
suppressWarnings(suppressMessages(library(optparse)))
suppressWarnings(suppressMessages(require(tidyverse)))
suppressWarnings(suppressMessages(library(dplyr)))
suppressWarnings(suppressMessages(library(phyloseq)))
opt = NULL
opt$input = "/Users/khaled/Desktop/sequencers_part2/Andrew_ASVs/tsv/27F_ASV_filtered.tsv"
input$mapping = "/Users/khaled/Desktop/sequencers_part2/Andrew_ASVs/27F_ASV_filtered.txt"
opt$input = "/Users/khaled/Desktop/sequencers_part2/Andrew_ASVs/tsv/27F_ASV_filtered.tsv"
input$mapping = "/Users/khaled/Desktop/sequencers_part2/Andrew_ASVs/27F_ASV_filtered.txt"
opt$mapping = "/Users/khaled/Desktop/sequencers_part2/Andrew_ASVs/27F_ASV_filtered.txt"
opt$groups - "category"
opt$groups = "category"
biomFile = opt$input
mappingFile = opt$mapping
condition = opt$groups
load_phylo = function(myPhyloseqObject){
# Load and format tables
myBiomTSV = myPhyloseqObject@otu_table@.Data
featureNames = row.names(myBiomTSV) %>% as.matrix()
myBiomTSV = as.data.frame(myBiomTSV)
row.names(myBiomTSV) = featureNames
myBiomTSV = myBiomTSV %>% t(.) %>% as.data.frame(.)
return(myBiomTSV)
}
biom = suppressMessages(readr::read_tsv(biomFile)) %>% as.data.frame(.)
rownames(biom) = biom[,1]
biom[,1] = NULL
biom = otu_table(biom, taxa_are_rows = TRUE)
each group at a time
mapping = import_qiime_sample_data(mappingFile)
mapping = import_qiime_sample_data(mappingFile)
mapping = import_qiime_sample_data(mappingFile)
