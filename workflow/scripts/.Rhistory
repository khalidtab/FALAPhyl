}
print("Processing pairing")
if (!is.null(paired))
paired <- as.factor(paired)
print("Converting count_table to matrix")
count_table <- as.matrix(count_table)
print(paste("Dimensions of count_table:", dim(count_table)))
if (is.null(test))
stop("'test' has to be specified")
print("Checking count_table for integers")
if (relative)
if (!isTRUE(all(unlist(count_table) == floor(unlist(count_table)))))
stop("count_table must only contain integer values")
print("Checking count_table for negatives")
if (min(count_table) < 0)
stop("count_table contains negative values")
print("Checking for empty samples")
if (sum(colSums(count_table) == 0) > 0)
stop("Some samples are empty")
print("Checking count_table and predictor consistency")
if (ncol(count_table) != length(predictor))
stop("Number of samples in count_table does not match length of predictor")
print("Checking predictor levels")
if (length(unique(predictor)) < 2)
stop("predictor should have at least two levels")
print("Checking test length")
if (length(test) != 1)
stop("'test' has to have length 1")
print("Verbose output")
if (verbose)
message(paste("Running on", cores, "cores"))
print("Removing empty features")
if (sum(rowSums(count_table) == 0) != 0)
message(paste(sum(rowSums(count_table) == 0), "empty features removed"))
count_table <- count_table[rowSums(count_table) > 0, ]
print(paste("Dimensions of count_table after filtering:", dim(count_table)))
if (nrow(count_table) <= 15)
warning("Dataset contains very few features")
print("Setting k parameter")
if (is.null(k)) {
k <- rep(round(nrow(count_table) * 0.02), 3)
if (sum(k) < 15) {
k <- c(5, 5, 5)
}
}
if (sum(k) == nrow(count_table))
stop("Set to spike all features. Change k argument")
if (sum(k) > nrow(count_table))
stop("Set to spike more features than are present in the data. Change k argument")
print("Checking spike settings")
if (sum(k) < 15 & sum(k) >= 10 & R <= 10)
message("Few features spiked. Increase 'k' or set 'R' to more than 10 to ensure proper estimations")
if (sum(k) < 10 & sum(k) >= 5 & R <= 20)
message("Few features spiked. Increase 'k' or set 'R' to more than 20 to ensure proper estimations")
if (sum(k) < 5 & R <= 50)
message("Very few features spiked. Increase 'k' or set 'R' to more than 50 to ensure proper estimations")
if (sum(k) > nrow(count_table)/2)
message("Set to spike more than half of the dataset, which might give unreliable estimates, Change k argument")
print("Checking predictor for NAs")
if (verbose)
if (any(is.na(predictor)))
warning("Predictor contains NAs!")
print("Handling predictor types")
if (is.numeric(predictor[1])) {
num.pred <- TRUE
if (verbose)
message(paste("predictor is assumed to be a quantitative variable, ranging from",
min(predictor, na.rm = TRUE), "to", max(predictor,
na.rm = TRUE)))
if (length(levels(as.factor(predictor))) == 2) {
ANSWER <- readline("The predictor is quantitative, but only contains 2 unique values. Are you sure this is correct? Enter y to proceed ")
if (ANSWER != "y")
stop("Wrap the predictor with as.factor(predictor) to treat it is a categorical variable")
}
}
else {
num.pred <- FALSE
if (length(levels(as.factor(predictor))) > length(unique(predictor)))
stop("predictor has more levels than unique values!")
if (verbose)
message(paste("predictor is assumed to be a categorical variable with",
length(unique(predictor)), "levels:", paste(levels(as.factor(predictor)),
collapse = ", ")))
}
print("Handling pairing variable")
if (!is.null(paired)) {
if (verbose)
message(paste("The paired variable has", length(unique(paired)),
"levels"))
}
print("Setting out.all parameter")
if (is.null(out.all)) {
if (length(unique(predictor)) == 2)
out.all <- FALSE
if (length(unique(predictor)) > 2)
out.all <- TRUE
if (num.pred)
out.all <- FALSE
}
print("Handling covariates")
if (!is.null(covars)) {
for (i in seq_along(covars)) {
if (verbose)
if (any(is.na(covars[[i]])))
warning(names(covars)[i], "contains NAs!")
if (is.numeric(covars[[i]][1])) {
if (verbose)
message(paste(names(covars)[i], "is assumed to be a quantitative variable, ranging from",
min(covars[[i]], na.rm = TRUE), "to", max(covars[[i]],
na.rm = TRUE)))
}
else {
if (verbose)
message(paste(names(covars)[i], "is assumed to be a categorical variable with",
length(unique(covars[[i]])), "levels:", paste(levels(as.factor(covars[[i]])),
collapse = ", ")))
}
}
}
print("Starting spiking process")
if (is.null(paired)) {
rands <- lapply(seq_len(R), function(x) sample(predictor))
}
else {
rands <- lapply(seq_len(R), function(x) unsplit(lapply(split(predictor,
paired), sample), paired))
}
print("Generating spiked datasets")
spikeds.l <- list()
for (eff in seq_along(effectSizes)) {
spikeds.l[[eff]] <- lapply(seq_len(R), function(x) spikein(count_table,
rands[[x]], effectSizes[eff], k, num.pred, relative))
}
print("Combining spiked datasets")
spikeds <- do.call(c, spikeds.l)
count_tables <- lapply(seq_len(R * length(effectSizes)),
function(x) spikeds[[x]][[1]])
print("Setting up parallel processing")
tests.par <- paste0(unlist(lapply(effectSizes, function(x) rep(x,
R))), "-", rep(paste0(seq_len(R), "_", rep(test, R)),
R))
pb <- txtProgressBar(max = length(tests.par), style = 3)
progress <- function(n) setTxtProgressBar(pb
powerDA2(
powerDA2(df,vec,test = "zzz",cores = 1,args = list(zzz = list(FUN = CPLM)),relative = TRUE, verbose = TRUE,p.adj = "fdr")
powerDA2 <- function (data, predictor, paired = NULL, covars = NULL, test = NULL,
effectSizes = c(2, 4, 8, 16, 32), alpha.p = 0.05, alpha.q = 0.1,
p.adj = "fdr", R = 5, relative = TRUE, k = NULL, cores = (detectCores() -
1), args = list(), out.all = NULL, core.check = TRUE,
verbose = TRUE)
{
print("Starting powerDA function")
stopifnot(exists("data"), exists("predictor"))
print("Checking core settings")
if (core.check) {
if (cores > 20) {
ANSWER <- readline(paste("You are about to run testDA using",
cores, "cores. Enter y to proceed "))
if (ANSWER != "y")
stop("Process aborted")
}
}
print("Processing input data")
if (is(data, "phyloseq")) {
DAdata <- DA.phyloseq(data, predictor, paired, covars)
count_table <- DAdata$count_table
predictor <- DAdata$predictor
paired <- DAdata$paired
covars <- DAdata$covars
}
else {
count_table <- data
}
print("Checking covariates")
if (!is.null(covars)) {
for (i in seq_along(covars)) {
assign(names(covars)[i], covars[[i]])
}
}
print("Processing pairing")
if (!is.null(paired))
paired <- as.factor(paired)
print("Converting count_table to matrix")
count_table <- as.matrix(count_table)
print(paste("Dimensions of count_table:", dim(count_table)))
if (is.null(test))
stop("'test' has to be specified")
print("Checking count_table for integers")
if (relative)
if (!isTRUE(all(unlist(count_table) == floor(unlist(count_table)))))
stop("count_table must only contain integer values")
print("Checking count_table for negatives")
if (min(count_table) < 0)
stop("count_table contains negative values")
print("Checking for empty samples")
if (sum(colSums(count_table) == 0) > 0)
stop("Some samples are empty")
print("Checking count_table and predictor consistency")
if (ncol(count_table) != length(predictor))
stop("Number of samples in count_table does not match length of predictor")
print("Checking predictor levels")
if (length(unique(predictor)) < 2)
stop("predictor should have at least two levels")
print("Checking test length")
if (length(test) != 1)
stop("'test' has to have length 1")
print("Verbose output")
if (verbose)
message(paste("Running on", cores, "cores"))
print("Removing empty features")
if (sum(rowSums(count_table) == 0) != 0)
message(paste(sum(rowSums(count_table) == 0), "empty features removed"))
count_table <- count_table[rowSums(count_table) > 0, ]
print(paste("Dimensions of count_table after filtering:", dim(count_table)))
if (nrow(count_table) <= 15)
warning("Dataset contains very few features")
print("Setting k parameter")
if (is.null(k)) {
k <- rep(round(nrow(count_table) * 0.02), 3)
if (sum(k) < 15) {
k <- c(5, 5, 5)
}
}
if (sum(k) == nrow(count_table))
stop("Set to spike all features. Change k argument")
if (sum(k) > nrow(count_table))
stop("Set to spike more features than are present in the data. Change k argument")
print("Checking spike settings")
if (sum(k) < 15 & sum(k) >= 10 & R <= 10)
message("Few features spiked. Increase 'k' or set 'R' to more than 10 to ensure proper estimations")
if (sum(k) < 10 & sum(k) >= 5 & R <= 20)
message("Few features spiked. Increase 'k' or set 'R' to more than 20 to ensure proper estimations")
if (sum(k) < 5 & R <= 50)
message("Very few features spiked. Increase 'k' or set 'R' to more than 50 to ensure proper estimations")
if (sum(k) > nrow(count_table)/2)
message("Set to spike more than half of the dataset, which might give unreliable estimates, Change k argument")
print("Checking predictor for NAs")
if (verbose)
if (any(is.na(predictor)))
warning("Predictor contains NAs!")
print("Handling predictor types")
if (is.numeric(predictor[1])) {
num.pred <- TRUE
if (verbose)
message(paste("predictor is assumed to be a quantitative variable, ranging from",
min(predictor, na.rm = TRUE), "to", max(predictor,
na.rm = TRUE)))
if (length(levels(as.factor(predictor))) == 2) {
ANSWER <- readline("The predictor is quantitative, but only contains 2 unique values. Are you sure this is correct? Enter y to proceed ")
if (ANSWER != "y")
stop("Wrap the predictor with as.factor(predictor) to treat it is a categorical variable")
}
}
else {
num.pred <- FALSE
if (length(levels(as.factor(predictor))) > length(unique(predictor)))
stop("predictor has more levels than unique values!")
if (verbose)
message(paste("predictor is assumed to be a categorical variable with",
length(unique(predictor)), "levels:", paste(levels(as.factor(predictor)),
collapse = ", ")))
}
print("Handling pairing variable")
if (!is.null(paired)) {
if (verbose)
message(paste("The paired variable has", length(unique(paired)),
"levels"))
}
print("Setting out.all parameter")
if (is.null(out.all)) {
if (length(unique(predictor)) == 2)
out.all <- FALSE
if (length(unique(predictor)) > 2)
out.all <- TRUE
if (num.pred)
out.all <- FALSE
}
print("Handling covariates")
if (!is.null(covars)) {
for (i in seq_along(covars)) {
if (verbose)
if (any(is.na(covars[[i]])))
warning(names(covars)[i], "contains NAs!")
if (is.numeric(covars[[i]][1])) {
if (verbose)
message(paste(names(covars)[i], "is assumed to be a quantitative variable, ranging from",
min(covars[[i]], na.rm = TRUE), "to", max(covars[[i]],
na.rm = TRUE)))
}
else {
if (verbose)
message(paste(names(covars)[i], "is assumed to be a categorical variable with",
length(unique(covars[[i]])), "levels:", paste(levels(as.factor(covars[[i]])),
collapse = ", ")))
}
}
}
print("Starting spiking process")
if (is.null(paired)) {
rands <- lapply(seq_len(R), function(x) sample(predictor))
}
else {
rands <- lapply(seq_len(R), function(x) unsplit(lapply(split(predictor,
paired), sample), paired))
}
print("Generating spiked datasets")
spikeds.l <- list()
for (eff in seq_along(effectSizes)) {
spikeds.l[[eff]] <- lapply(seq_len(R), function(x) spikein(count_table,
rands[[x]], effectSizes[eff], k, num.pred, relative))
}
print("Combining spiked datasets")
spikeds <- do.call(c, spikeds.l)
count_tables <- lapply(seq_len(R * length(effectSizes)),
function(x) spikeds[[x]][[1]])
print("Setting up parallel processing")
tests.par <- paste0(unlist(lapply(effectSizes, function(x) rep(x,
R))), "-", rep(paste0(seq_len(R), "_", rep(test, R)),
R))
pb <- txtProgressBar(max = length(tests.par), style = 3)
progress <- function(n) setTxtProgressBar(pb
powerDA
testDA
?testDA
powerDA(df, predictor = vec, test = "tta")
final = "effect size power calculation is not available for the chosen test"
summary(final)
final$text = "effect size power calculation is not available for the chosen test"
final = NA
final$text = "effect size power calculation is not available for the chosen test"
summary(final)
?summary
final = NA
summary(final)
?DAtest::testDA
?format
format(Sys.time(), "%Y%m%d_%H%M%S")
format(Sys.time(), "%Y%m%d_%H%M%S%SS")
??zcpglm
?statmod
statmo::zcpglm
statmod::zcpglm
cplm
?cplm
devtools::install_version("cplm", version = "0.7-5", repos = "http://cran.us.r-project.org")
devtools::install_version("cplm", version = "0.7-5", repos = "http://cran.us.r-project.org")
library("DAtest")
?testDA
testDA
testDA
library("DAtest")
library("tidyverse")
opt = NULL
opt$input = "/Users/khaled/Library/CloudStorage/GoogleDrive-altabtba@ualberta.ca/My Drive/Lab/Anjali - gingivitis21/July_26 for pairwise falaphyl trial/tmp/diff/july21–condition–minAbd0.001minR5minS2/pairwise/Control_Plaque!Control_Tissues.tsv"
df = opt$input
df = read_tsv(df)
dfRows = as.data.frame(df[,1])
df = as.data.frame(df)
rownames(df) = dfRows[,1]
df[,1] = NULL
df[] = lapply(df, as.numeric)
opt$mapping = "/Users/khaled/Library/CloudStorage/GoogleDrive-altabtba@ualberta.ca/My Drive/Lab/Anjali - gingivitis21/July_26 for pairwise falaphyl trial/tmp/diff/july21–condition–minAbd0.001minR5minS2/pairwise/Control_Plaque!Control_Tissues.txt"
map = opt$mapping
map = read.csv(map,sep="\t") %>% as.data.frame(.)
View(map)
opt$category = "condition"
category = opt$category
catNum = which(colnames(map) == category)
working_map = cbind(as.character(map[,1]),
as.character(map[,catNum])) %>% as.data.frame(.)
colnames(working_map) = c("SampleID","condition")
vec = working_map$condition %>% as.factor(.)
testDA(df, predictor = vec,tests=c("kru","msf"))
testDA(df, predictor = vec,tests=c("kru","ltt2"))
length(vec)
View(df)
df = opt$input
df = read_tsv(df)
df = opt$input
df = read_tsv(df)
dfRows = as.data.frame(df[,1])
df = as.data.frame(df)
rownames(df) = dfRows[,1]
df[,1] = NULL
df[] = lapply(df, as.numeric)
df = t(df) %>% as.data.frame(.)
map = opt$mapping
map = read.csv(map,sep="\t") %>% as.data.frame(.)
category = opt$category
catNum = which(colnames(map) == category)
working_map = cbind(as.character(map[,1]),
as.character(map[,catNum])) %>% as.data.frame(.)
colnames(working_map) = c("SampleID","condition")
vec = working_map$condition %>% as.factor(.)
testDA(df, predictor = vec,tests=c("kru","abc"))
testDA(df, predictor = vec,tests=c("abc"))
testDA(df, predictor = vec,tests=c("kru","ltt2"))
View(dfRows)
?weedieverse::Tweedieverse
?Tweedieverse::Tweedieverse
df <- apply(df, 2, function(x) x / sum(x))
colSums(df)
CPLM <- function(count_table, predictor, paired, covars) {
# Create a unique output directory based on timestamp
timestamp <- format(Sys.time(), "%Y%m%d_%H%M%S")
output_dir <- paste0(tmp_folder, timestamp)
dir.create(output_dir, recursive = TRUE)
results_file <- paste0(output_dir, "/all_results.tsv")
print("Entering function")
# Debug: Print inputs
print("count_table:")
print(paste(capture.output(head(count_table)), collapse = "\n"))
print(paste("Dimensions of count_table:", paste(dim(count_table), collapse = " x ")))
print("predictor:")
print(paste(capture.output(head(predictor)), collapse = "\n"))
print(paste("Length of predictor:", length(predictor)))
# Prepare the predictor data frame
predictor_df <- data.frame(sampleid = colnames(count_table), metadata = as.character(predictor))
rownames(predictor_df) <- predictor_df$sampleid
predictor_df$sampleid <- NULL
print("predictor_df:")
print(paste(capture.output(head(predictor_df)), collapse = "\n"))
print(paste("Dimensions of predictor_df:", paste(dim(predictor_df), collapse = " x ")))
# Run the Tweedieverse function
print("Running Tweedieverse...")
tryCatch({
Tweedieverse::Tweedieverse(
input_features = as.data.frame(count_table),
input_metadata = predictor_df,
output = output_dir,
base_model = mymethod,
abd_threshold = 0,
prev_threshold = 0.0,
var_threshold = 0,
entropy_threshold = 0,
)
print("Tweedieverse completed.")
}, error = function(e) {
print(paste("Error in Tweedieverse:", e$message))
return(NULL)
})
# Check if the results file was created
if (!file.exists(results_file)) {
print("Results file does not exist")
stop("Results file does not exist")
}
print("Results file exists.")
# Read the results
myTable <- read_tsv(results_file, show_col_types = FALSE)
myTable <- as.data.frame(myTable)
# Debug: Check myTable
print("myTable:")
print(paste(capture.output(head(myTable)), collapse = "\n"))
print(paste("Dimensions of myTable:", paste(dim(myTable), collapse = " x ")))
# Ensure myTable has the expected structure
if (nrow(myTable) == 0 || !all(c("feature", "pval") %in% colnames(myTable))) {
print("Results table has unexpected structure")
stop("Results table has unexpected structure")
}
# Define a result data frame
result_df <- data.frame(
Feature = myTable$feature,
pval = myTable$pval,
pval.adj = p.adjust(myTable$pval, method = "fdr"),
Method = "CPLM",
stringsAsFactors = FALSE
)
rownames(result_df) <- result_df$Feature
print("Returning result_df from CPLM")
print(paste(capture.output(head(result_df)), collapse = "\n"))
return(result_df)
}
final <- DAtest::testDA(
data = df,
predictor = vec,
tests = c("zzz"),
args = list(zzz = list(FUN = CPLM)), relative = TRUE)
final <- DAtest::testDA(
data = df,
predictor = vec,
tests = c("zzz"),
args = list(zzz = list(FUN = CPLM)), relative = FALSE)
?print
tmp_folder
tmp_folder = "/Users/khaled/Library/CloudStorage/GoogleDrive-altabtba@ualberta.ca/My Drive/Lab/Anjali - gingivitis21/July_26 for pairwise falaphyl trial"
timestamp <- format(Sys.time(), "%Y%m%d_%H%M%S")
output_dir <- paste0(tmp_folder, timestamp)
dir.create(output_dir, recursive = TRUE)
results_file <- paste0(output_dir, "/all_results.tsv")
results_file
DAtest::testDA(
data = df,
predictor = vec,
tests = c("zzz"),
args = list(zzz = list(FUN = CPLM)), relative = FALSE)
DAtest::testDA(
data = df,
predictor = vec,
tests = c("zzz"),
args = list(zzz = list(FUN = CPLM)), relative = FALSE, cores = 1)
mymethod = "CPLM"
DAtest::testDA(
data = df,
predictor = vec,
tests = c("zzz"),
args = list(zzz = list(FUN = CPLM)), relative = FALSE)
DAtest::testDA(
data = df,
predictor = vec,
tests = c("zzz"),
args = list(zzz = list(FUN = CPLM)), relative = FALSE, cores = 1)
?Tweedieverse::Tweedieverse()
