mypvalue =  as.data.frame(mypvalue)
row.names(mypvalue) = mypvalue[,1]
mypvalue$`#OTU ID` = NULL # by now, row names and column names are the feature ID
mypvalue = as.matrix(mypvalue)
mypvalue = replace(mypvalue, lower.tri(mypvalue, TRUE), NA)
mypvalue = reshape2::melt(mypvalue, na.rm = TRUE)
colnames(mypvalue) = c("Source","Target","pvalue")
myTable = merge(myInput,mypvalue)
Type = rep("Undirected", length(rownames(myTable)))
myTable = cbind(myTable,Type)
myTable = cbind(myTable, abs(myTable$corrWeight))
myTable = subset(myTable, abs(myTable$corrWeight) >= threshold) # Subset to only correlations that fit the criteria
myTable$`abs(myTable$corrWeight)` = NULL
View(myTable)
myInput = suppressMessages(read_tsv(input))
myInput =  as.data.frame(myInput)
row.names(myInput) = myInput[,1]
myInput$`#OTU ID` = NULL # by now, row names and column names are the feature ID
myInput = as.matrix(myInput)
myInput = replace(myInput, lower.tri(myInput, TRUE), NA)
myInput = reshape2::melt(myInput, na.rm = TRUE)
colnames(myInput) = c("Source","Target","corrWeight")
# Unpack/Melt the pvalue matrix table
mypvalue = suppressMessages(read_tsv(pvalue))
mypvalue =  as.data.frame(mypvalue)
row.names(mypvalue) = mypvalue[,1]
mypvalue$`#OTU ID` = NULL # by now, row names and column names are the feature ID
mypvalue = as.matrix(mypvalue)
mypvalue = replace(mypvalue, lower.tri(mypvalue, TRUE), NA)
mypvalue = reshape2::melt(mypvalue, na.rm = TRUE)
colnames(mypvalue) = c("Source","Target","pvalue")
myTable = merge(myInput,mypvalue)
Type = rep("Undirected", length(rownames(myTable)))
myTable = cbind(myTable,Type)
View(myTable)
myTable = cbind(myTable, abs(myTable$corrWeight))
myTable = subset(myTable, abs(myTable$corrWeight) >= threshold) # Subset to only correlations that fit the criteria
myTable$`abs(myTable$corrWeight)` = NULL
pvaluethreshold
pvaluethreshold = 0.05
myTable = subset(myTable, abs(myTable$pvalue) < pvaluethreshold)
weight = myTable$corrWeight
myTable = cbind(myTable,weight)
myTable$weight[myTable$weight < 0] = 0 # This way, the louvain modularity function below will not consider negative correlations between two edges as a positive correlation and be influenced to place them in the same cluster
row.names(myTable) = NULL # At this point, you have a pairwise table that was filtered to the level specified
tableForModularity = myTable
tableForModularity = subset(tableForModularity, tableForModularity$weight != 0) # Subset to only correlations that are positive
View(tableForModularity)
tableForModularity = subset(tableForModularity, tableForModularity$Source != "Others") # Remove others so it doesn't mess up the Louvain algorithm
View(tableForModularity)
myigraph = graph.data.frame(tableForModularity, directed = FALSE)
myModularity = cluster_louvain(myigraph) #Same method as Gephi
nodesList = cbind(myModularity$names,myModularity$membership)
colnames(nodesList) = c("Id","Community")
nodesList = as.data.frame(nodesList)
# To make it easier to do the Zi-Pi calculations for each OTU, copy myTable to another, and append it with the "Target" OTU being the "Source"
myTable$weight = NULL
newTable = myTable
colnames(newTable) = c("Target","Source","corrWeight","pvalue","Type")
newTable = cbind(newTable$Source,newTable$Target,
newTable$corrWeight,newTable$pvalue,
as.character(newTable$Type))
colnames(newTable) = c("Source","Target","corrWeight","pvalue","Type")
newTable = as.data.frame(newTable, stringsAsFactors=FALSE)
myTable2 = rbind(newTable,myTable)
View(myTable2)
#Combine nodesList to the myTable2 to make it easier subset the table
Source = nodesList %>% as.data.frame()
colnames(Source) = c("Source","SourceCommunity")
myTable2 = merge(myTable2,Source)
Target = nodesList %>% as.data.frame()
colnames(Target) = c("Target","TargetCommunity")
myTable2 = merge(myTable2,Target)
colnames(myTable2) = c("Target","Source","Weight","pvalue",
"Type","SourceCommunity","TargetCommunity")
myTable = myTable2
View(newTable)
rm(myTable2,Source, Target, newTable,myigraph,
Type,mypvalue,myInput,weight,input,pvalue)
zipiTable = matrix(NA, ncol = 3, nrow = length(nodesList$Id)) %>% as.data.frame(.,stringsAsFactors=FALSE)
colnames(zipiTable) = c("Id","Zi","Pi")
zipiTable$Id = nodesList$Id
View(zipiTable)
myCommunities = unique(myTable$SourceCommunity) %>% as.character(.)
#Zi calculations
for (x in (1:length(myCommunities))){
## Leave only edges coming from nodes in the same community
myComm = myCommunities[x] %>% as.character(.)
currentComm = subset(myTable, SourceCommunity==myComm)
currentComm = subset(currentComm, TargetCommunity==myComm)
if (dim(currentComm)[1] == 0){next} #Break out if the current Community has only negative edges to other nodes, or if the node doesn't have any edges to nodes within the same community. These communities don't get reported through this method.
uniq_comm_ids = c(unique(currentComm$Source),unique(currentComm$Target))
comm_zi = matrix(NA, ncol = 7, nrow = length(uniq_comm_ids)) %>% as.data.frame(.,stringsAsFactors=FALSE)
colnames(comm_zi) = c("Id","NumOfSourceConnections","NumOfTargetConnections","NumOfConnections","average","STDev","Zi")
comm_zi$Id = uniq_comm_ids
for (xx in uniq_comm_ids){ # For source
myNum = subset(currentComm, Source==xx)
myNum = dim(myNum)
myNum = myNum[1]
comm_zi = within(comm_zi, NumOfSourceConnections[Id == xx] <- myNum)
}
for (xx in uniq_comm_ids){ # For target
myNum = subset(currentComm, Target==xx)
myNum = dim(myNum)
myNum = myNum[1]
comm_zi = within(comm_zi, NumOfTargetConnections[Id == xx] <- myNum)
}
comm_zi$NumOfConnections = comm_zi$NumOfSourceConnections + comm_zi$NumOfTargetConnections
comm_zi$NumOfSourceConnections = NULL
comm_zi$NumOfTargetConnections = NULL
comm_zi_STDEV = sd(comm_zi$NumOfConnections)
myCommunities = unique(myTable$SourceCommunity) %>% as.character(.)
#Zi calculations
for (x in (1:length(myCommunities))){
## Leave only edges coming from nodes in the same community
myComm = myCommunities[x] %>% as.character(.)
currentComm = subset(myTable, SourceCommunity==myComm)
currentComm = subset(currentComm, TargetCommunity==myComm)
if (dim(currentComm)[1] == 0){next} #Break out if the current Community has only negative edges to other nodes, or if the node doesn't have any edges to nodes within the same community. These communities don't get reported through this method.
uniq_comm_ids = c(unique(currentComm$Source),unique(currentComm$Target))
comm_zi = matrix(NA, ncol = 7, nrow = length(uniq_comm_ids)) %>% as.data.frame(.,stringsAsFactors=FALSE)
colnames(comm_zi) = c("Id","NumOfSourceConnections","NumOfTargetConnections","NumOfConnections","average","STDev","Zi")
comm_zi$Id = uniq_comm_ids
for (xx in uniq_comm_ids){ # For source
myNum = subset(currentComm, Source==xx)
myNum = dim(myNum)
myNum = myNum[1]
comm_zi = within(comm_zi, NumOfSourceConnections[Id == xx] <- myNum)
}
for (xx in uniq_comm_ids){ # For target
myNum = subset(currentComm, Target==xx)
myNum = dim(myNum)
myNum = myNum[1]
comm_zi = within(comm_zi, NumOfTargetConnections[Id == xx] <- myNum)
}
comm_zi$NumOfConnections = comm_zi$NumOfSourceConnections + comm_zi$NumOfTargetConnections
comm_zi$NumOfSourceConnections = NULL
comm_zi$NumOfTargetConnections = NULL
comm_zi_STDEV = sd(comm_zi$NumOfConnections)
if (is.na(comm_zi_STDEV) == TRUE){
comm_zi$Zi = 0 # Divide by zero is not allowed, therefore we are assigning it as zero instead.
} else if(comm_zi_STDEV == 0) {
comm_zi$Zi = 0 # Divide by zero is not allowed, therefore we are assigning it as zero instead.
} else {
comm_zi$STDev = comm_zi_STDEV
comm_zi$average = ave(comm_zi$NumOfConnections)
comm_zi$Zi = (comm_zi$NumOfConnections - comm_zi$average)/comm_zi$STDev
}
)
for (x in (1:length(myCommunities))){
## Leave only edges coming from nodes in the same community
myComm = myCommunities[x] %>% as.character(.)
currentComm = subset(myTable, SourceCommunity==myComm)
currentComm = subset(currentComm, TargetCommunity==myComm)
if (dim(currentComm)[1] == 0){next} #Break out if the current Community has only negative edges to other nodes, or if the node doesn't have any edges to nodes within the same community. These communities don't get reported through this method.
uniq_comm_ids = c(unique(currentComm$Source),unique(currentComm$Target))
comm_zi = matrix(NA, ncol = 7, nrow = length(uniq_comm_ids)) %>% as.data.frame(.,stringsAsFactors=FALSE)
colnames(comm_zi) = c("Id","NumOfSourceConnections","NumOfTargetConnections","NumOfConnections","average","STDev","Zi")
comm_zi$Id = uniq_comm_ids
for (xx in uniq_comm_ids){ # For source
myNum = subset(currentComm, Source==xx)
myNum = dim(myNum)
myNum = myNum[1]
comm_zi = within(comm_zi, NumOfSourceConnections[Id == xx] <- myNum)
}
for (xx in uniq_comm_ids){ # For target
myNum = subset(currentComm, Target==xx)
myNum = dim(myNum)
myNum = myNum[1]
comm_zi = within(comm_zi, NumOfTargetConnections[Id == xx] <- myNum)
}
comm_zi$NumOfConnections = comm_zi$NumOfSourceConnections + comm_zi$NumOfTargetConnections
comm_zi$NumOfSourceConnections = NULL
comm_zi$NumOfTargetConnections = NULL
comm_zi_STDEV = sd(comm_zi$NumOfConnections)
if (is.na(comm_zi_STDEV) == TRUE){
comm_zi$Zi = 0 # Divide by zero is not allowed, therefore we are assigning it as zero instead.
} else if(comm_zi_STDEV == 0) {
comm_zi$Zi = 0 # Divide by zero is not allowed, therefore we are assigning it as zero instead.
} else {
comm_zi$STDev = comm_zi_STDEV
comm_zi$average = ave(comm_zi$NumOfConnections)
comm_zi$Zi = (comm_zi$NumOfConnections - comm_zi$average)/comm_zi$STDev
}
comm_zi$NumOfConnections = NULL
comm_zi$average = NULL
comm_zi$STDev = NULL
zipiTable = merge(zipiTable,comm_zi, by="Id", all.x = TRUE, all.y = TRUE)
myValues = coalesce(as.double(zipiTable$Zi.y),as.double(zipiTable$Zi.x))
zipiTable$Zi.x = NULL
colnames(zipiTable) = c("Id","Pi","Zi")
zipiTable$Zi = myValues
}
rm(comm_zi,comm_zi_STDEV,currentComm,myComm,myCommunities,myNum,myValues,uniq_comm_ids,x,xx)
View(zipiTable)
zipiTable = unique(zipiTable) # There are some duplicate measurements of the table, so only keep unique ones
for (x in nodesList$Id){
# x = nodesList$Id[2]
piTotalTableSource = subset(myTable, Source==x)
piTotalTableTarget = subset(myTable, Target==x)
colnames(piTotalTableTarget) = c("Source","Target","Weight","pvalue","Type","TargetCommunity","SourceCommunity") # Change the target to a source, including the community
piTotalTable = rbind(piTotalTableSource,piTotalTableTarget)
total = dim(piTotalTable)[1]
sigma = 0
for (y in unique(piTotalTable$TargetCommunity)){
commConnections = subset(piTotalTable, TargetCommunity==y) %>% dim(.) %>% .[1]
fraction = (commConnections/total)^2
sigma = sigma + fraction
}
featurePiScore = 1-sigma
zipiTable = within(zipiTable, Pi[Id == x] <- featurePiScore)
}
zipiTable = merge(zipiTable,nodesList)
rm(x,y,total,sigma,piTotalTable,myModularity,fraction,featurePiScore,nodesList,commConnections)
View(zipiTable)
View(myTable)
opt = NULL
opt$input = zipiTable
opt$threshold = 0.1
opt$pvalue = 0.05
threshold = opt$threshold # threshold = "0.1"
pvalue = opt$pvalue # pvalue = "0.05"
pvalue$core = 0.5
opt$core = 0.5
core = opt$core # core = "0.8"
core = as.numeric(core)
zipiTableLabels = cbind(zipiTable,zipiTable$Id)
colnames(zipiTableLabels) = c("Id","Pi","Zi","Community","Label")
View(zipiTableLabels)
PiLabels = filter(zipiTableLabels,Pi>=0.62)
ZiLabels = filter(zipiTableLabels,Zi>=2.5)
labeledPoints = rbind(PiLabels,ZiLabels)
unlabeledPoints = subset(zipiTableLabels, !(Id %in% labeledPoints$Id))
unlabeledPoints$Label = ""
zipiTableLabels = rbind(unlabeledPoints,labeledPoints)
View(zipiTableLabels)
annotations <- data.frame(
xpos = c(-Inf,-Inf,Inf,Inf),
ypos =  c(-Inf, Inf,-Inf,Inf),
annotateText = c("Peripherals","Module hubs"
,"Connectors","Network hubs"),
hjustvar = c(0,0,1,1) ,
vjustvar = c(0,1,0,1)) #<- adjust
zipiPlot =  ggplot(zipiTableLabels, aes(x = Pi, y = Zi, label = Label)) +
geom_point(color = "dark blue", position = "jitter") + geom_hline(yintercept = 2.5, color = "dark green", size = 1) +
geom_vline(xintercept = 0.62, color = "orange", size = 1) +
labs(x = "Among modules connectivity (Pi)", y = "Within module connectivity (Zi") +
geom_text(data=annotations,aes(x=xpos,y=ypos,hjust=hjustvar,vjust=vjustvar,label=annotateText)) +
geom_label_repel(max.overlaps = 50) +
labs(title = paste0("ZiPi plot. # of nodes = ", length(zipiTable$Id),", Core = " ,(core*100),"%, Threshold = ",threshold, ", p-value < ",pvalue)) +
theme(plot.title = element_text(hjust = 0.5))
gt = ggplot_gtable(ggplot_build(zipiPlot))
gt$layout$clip[gt$layout$name == "panel"] <- "off"
library("optparse")
suppressWarnings(suppressMessages(library("dplyr")))
suppressWarnings(suppressMessages(library(tidyverse)))
suppressWarnings(suppressMessages(library(ggrepel)))
zipiPlot =  ggplot(zipiTableLabels, aes(x = Pi, y = Zi, label = Label)) +
geom_point(color = "dark blue", position = "jitter") + geom_hline(yintercept = 2.5, color = "dark green", size = 1) +
geom_vline(xintercept = 0.62, color = "orange", size = 1) +
labs(x = "Among modules connectivity (Pi)", y = "Within module connectivity (Zi") +
geom_text(data=annotations,aes(x=xpos,y=ypos,hjust=hjustvar,vjust=vjustvar,label=annotateText)) +
geom_label_repel(max.overlaps = 50) +
labs(title = paste0("ZiPi plot. # of nodes = ", length(zipiTable$Id),", Core = " ,(core*100),"%, Threshold = ",threshold, ", p-value < ",pvalue)) +
theme(plot.title = element_text(hjust = 0.5))
gt = ggplot_gtable(ggplot_build(zipiPlot))
gt$layout$clip[gt$layout$name == "panel"] <- "off"
gt
plot(gt)
pvaluethreshold
grid::grid.draw(gt)
grid::grid.draw(gt)
?grid
library(grid)
?library(grid)
?capitalize
??capital
suppressWarnings(suppressMessages(library(dplyr)))
suppressWarnings(suppressMessages(require(tidyverse)))
suppressWarnings(suppressMessages(library(optparse)))
suppressWarnings(suppressMessages(library(ggpubr)))
suppressWarnings(suppressMessages(library(ggplot2)))
suppressWarnings(suppressMessages(library(effectsize)))
opt = NULL
opt$category = "condition"
opt$distnace = "jaccard"
opt$patientID = "subjectID"
opt$input = "/Users/khaled/Documents/GitHub/FALAPhyl/data/distance/beta_div/jaccard_2–v35_oral_gs.tsv"
cond = opt$category
dist_type = opt$distance
patientID = opt$patientID
# Load distance
dist = opt$input
dist = suppressWarnings(suppressMessages(read_tsv(dist,progress = FALSE))) %>% as.matrix(.)
rownames(dist) = dist[,1]
dist = dist[, colnames(dist) != "X1"]
dist[upper.tri(dist)] = NA
dist = reshape2::melt(dist, na.rm = TRUE)
colnames(dist) = c("v1","v2",dist_type)
opt$repl = "/Users/khaled/Documents/GitHub/FALAPhyl/data/distance/beta_div/Repl–v35_oral_gs–jaccard.tsv"
repl = suppressWarnings(suppressMessages(read_tsv(repl,progress = FALSE))) %>% as.matrix(.)
rownames(repl) = repl[,1]
repl = repl[, colnames(repl) != "X1"]
repl[upper.tri(repl)] = NA
repl = reshape2::melt(repl, na.rm = TRUE)
colnames(repl) = c("v1","v2","repl")
repl = opt$repl
repl = suppressWarnings(suppressMessages(read_tsv(repl,progress = FALSE))) %>% as.matrix(.)
rownames(repl) = repl[,1]
repl = repl[, colnames(repl) != "X1"]
repl[upper.tri(repl)] = NA
repl = reshape2::melt(repl, na.rm = TRUE)
colnames(repl) = c("v1","v2","repl")
opt$norepl = "/Users/khaled/Documents/GitHub/FALAPhyl/data/distance/beta_div/NoRepl–v35_oral_gs–jaccard.tsv"
noRepl = opt$norepl
noRepl = suppressWarnings(suppressMessages(read_tsv(noRepl,progress = FALSE))) %>% as.matrix(.)
rownames(noRepl) = noRepl[,1]
noRepl = noRepl[, colnames(noRepl) != "X1"]
noRepl[upper.tri(noRepl)] = NA
noRepl = reshape2::melt(noRepl, na.rm = TRUE)
colnames(noRepl) = c("v1","v2","noRepl")
opt$mapping = "/Users/khaled/Documents/GitHub/FALAPhyl/data/v35_oral_gs.txt"
map = suppressMessages(read_tsv(map))
map = opt$mapping
map = suppressMessages(read_tsv(map))
opt$output = "/Users/khaled/Documents/GitHub/FALAPhyl/data/"
output = opt$output
distance = merge(dist,repl, all = TRUE) %>% merge(.,noRepl, all = TRUE)
sampleIDs = map[,1]
patientIDcolumn = which(colnames(map) == patientID)
patientIDcolumn = map[,patientIDcolumn]
sampleIDtable = cbind(sampleIDs,patientIDcolumn)
myConds = which(colnames(map) == cond) %>% map[,.] %>% as.matrix(.)
myUniqueConds = myConds %>% unique(.)
reducedMap = cbind(sampleIDs,myConds)
colnames(reducedMap) = cbind("v1","cond1")
distance = merge(distance, reducedMap, by.x=c("v1"), by.y=c("v1")) %>% merge(., reducedMap, by.x=c("v2"), by.y=c("v1"))
colnames(sampleIDtable) = c("v1","v1subjectID")
distance = merge(distance,sampleIDtable, by.x=c("v1"), by.y=c("v1"))
colnames(sampleIDtable) = c("v2","v2subjectID")
distance = merge(distance,sampleIDtable, by.x=c("v2"), by.y=c("v2"))
# Subset to only those from the same patient
distance = distance[distance$v1subjectID==distance$v2subjectID, ]
colnames(distance) = c("v2","v1",dist_type,"repl","noRepl","cond1","cond2","v1subjectID","v2subjectID")
uniqueCond = c(distance$cond1, distance$cond2) %>% unique(.)
comboUniq = combn(uniqueCond,2,simplify = FALSE)
for (myConds in comboUniq) {
myCond1 = myConds[1]
myCond2 = myConds[2]
table1 = subset(distance,cond1 == myCond1)
table1 = data.frame(table1$v1,table1$v2,table1[,3],table1$repl,table1$noRepl,table1$cond1,table1$cond2) # Rearrange the columns
colnames(table1) = c("v1","v2",dist_type,"repl","noRepl","cond1","cond2") # Fix the names of the columns
table2 = subset(distance,cond2 == myCond1)
colnames(table2) = c("v1","v2",dist_type,"repl","noRepl","cond2","cond1") # This makes table2 to have the same format as table1
table2 = data.frame(table2$v1,table2$v2,table2[,3],table2$repl,table2$noRepl,table2$cond1,table2$cond2) # Rearrange the columns
colnames(table2) = c("v1","v2",dist_type,"repl","noRepl","cond1","cond2") # Fix the names
myTable = rbind(table1,table2)
# By now myTable cond1 equals myCond1. Next, subset mytable so that cond2 equals myCond2
myTable = subset(myTable,cond2 == myCond2)
i = c(3,4,5)
myTable[,i] = apply(myTable[,i],2, function(x) as.numeric(as.character(x)))
rm(table1,table2)
effectSize = rank_biserial(myTable$repl,myTable$noRepl, paired = TRUE) %>% interpret(., rules = "funder2019")
pvalue = wilcox.test(myTable$repl,myTable$noRepl, paired = TRUE) %>% .$p.value
pd = data.frame(replacement = myTable$repl, noreplacement = myTable$noRepl)
numOfParticipants = dim(pd)[1]
if (dist_type == "bray"){
colnames(pd) = c("balanced variation in abundance","abundance gradients")
myGraph = ggpubr::ggpaired(pd, cond1 = "balanced variation in abundance", cond2 = "abundance gradients", fill = "condition", palette = "jco", line.size=0.01,
title= (paste(dist_type, "breakdown \n",myCond1,"and",myCond2, "\n Pvalue <",formatC(pvalue, format = "e", digits = 2))),
subtitle = paste0("n =",numOfParticipants,
". Wilcoxon signed rank sum test, P-value < ", formatC(pvalue, format = "e", digits = 5)),
". Rank biserial effect size= ",formatC(effectSize$r_rank_biserial, format = "g", digits = 2)
)} else {
colnames(pd) = c("Turn-over","Nestedness")
myGraph = ggpubr::ggpaired(pd, cond1 = "Turn-over", cond2 = "Nestedness", fill = "condition", palette = "jco", line.size=0.01,
title= (paste(dist_type, "breakdown\n",myCond1,"and",myCond2)),
subtitle = paste0("n =",numOfParticipants,
"\nWilcoxon signed rank sum test, P-value < ",formatC(pvalue, format = "e", digits = 5),
". Rank biserial effect size= ",formatC(effectSize$r_rank_biserial, format = "g", digits = 2))
)}
ggsave(filename=paste0(output,"/",myCond1,"_",myCond2,".svg"),plot=myGraph)
}
comboUniq
uniqueCond = c(distance$cond1, distance$cond2) %>% unique(.)
uniqueCond
View(distance)
dist_type
dist_type = opt$distance
dist_type
opt$distance = "jaccard"
colnames(distance) = c("v2","v1",dist_type,"repl","noRepl","cond1","cond2","v1subjectID","v2subjectID")
dist_type
dist_type = opt$distance
dist_type
colnames(distance) = c("v2","v1",dist_type,"repl","noRepl","cond1","cond2","v1subjectID","v2subjectID")
uniqueCond = c(distance$cond1, distance$cond2) %>% unique(.)
comboUniq = combn(uniqueCond,2,simplify = FALSE)
for (myConds in comboUniq) {
myCond1 = myConds[1]
myCond2 = myConds[2]
table1 = subset(distance,cond1 == myCond1)
table1 = data.frame(table1$v1,table1$v2,table1[,3],table1$repl,table1$noRepl,table1$cond1,table1$cond2) # Rearrange the columns
colnames(table1) = c("v1","v2",dist_type,"repl","noRepl","cond1","cond2") # Fix the names of the columns
table2 = subset(distance,cond2 == myCond1)
colnames(table2) = c("v1","v2",dist_type,"repl","noRepl","cond2","cond1") # This makes table2 to have the same format as table1
table2 = data.frame(table2$v1,table2$v2,table2[,3],table2$repl,table2$noRepl,table2$cond1,table2$cond2) # Rearrange the columns
colnames(table2) = c("v1","v2",dist_type,"repl","noRepl","cond1","cond2") # Fix the names
myTable = rbind(table1,table2)
# By now myTable cond1 equals myCond1. Next, subset mytable so that cond2 equals myCond2
myTable = subset(myTable,cond2 == myCond2)
i = c(3,4,5)
myTable[,i] = apply(myTable[,i],2, function(x) as.numeric(as.character(x)))
rm(table1,table2)
effectSize = rank_biserial(myTable$repl,myTable$noRepl, paired = TRUE) %>% interpret(., rules = "funder2019")
pvalue = wilcox.test(myTable$repl,myTable$noRepl, paired = TRUE) %>% .$p.value
pd = data.frame(replacement = myTable$repl, noreplacement = myTable$noRepl)
numOfParticipants = dim(pd)[1]
if (dist_type == "bray"){
colnames(pd) = c("balanced variation in abundance","abundance gradients")
myGraph = ggpubr::ggpaired(pd, cond1 = "balanced variation in abundance", cond2 = "abundance gradients", fill = "condition", palette = "jco", line.size=0.01,
title= (paste(dist_type, "breakdown \n",myCond1,"and",myCond2, "\n Pvalue <",formatC(pvalue, format = "e", digits = 2))),
subtitle = paste0("n =",numOfParticipants,
". Wilcoxon signed rank sum test, P-value < ", formatC(pvalue, format = "e", digits = 5)),
". Rank biserial effect size= ",formatC(effectSize$r_rank_biserial, format = "g", digits = 2)
)} else {
colnames(pd) = c("Turn-over","Nestedness")
myGraph = ggpubr::ggpaired(pd, cond1 = "Turn-over", cond2 = "Nestedness", fill = "condition", palette = "jco", line.size=0.01,
title= (paste(dist_type, "breakdown\n",myCond1,"and",myCond2)),
subtitle = paste0("n =",numOfParticipants,
"\nWilcoxon signed rank sum test, P-value < ",formatC(pvalue, format = "e", digits = 5),
". Rank biserial effect size= ",formatC(effectSize$r_rank_biserial, format = "g", digits = 2))
)}
ggsave(filename=paste0(output,"/",myCond1,"_",myCond2,".svg"),plot=myGraph)
}
comboUniq
for (myConds in comboUniq) {
myCond1 = myConds[1]
myCond2 = myConds[2]
table1 = subset(distance,cond1 == myCond1)
table1 = data.frame(table1$v1,table1$v2,table1[,3],table1$repl,table1$noRepl,table1$cond1,table1$cond2) # Rearrange the columns
colnames(table1) = c("v1","v2",dist_type,"repl","noRepl","cond1","cond2") # Fix the names of the columns
table2 = subset(distance,cond2 == myCond1)
colnames(table2) = c("v1","v2",dist_type,"repl","noRepl","cond2","cond1") # This makes table2 to have the same format as table1
table2 = data.frame(table2$v1,table2$v2,table2[,3],table2$repl,table2$noRepl,table2$cond1,table2$cond2) # Rearrange the columns
colnames(table2) = c("v1","v2",dist_type,"repl","noRepl","cond1","cond2") # Fix the names
myTable = rbind(table1,table2)
# By now myTable cond1 equals myCond1. Next, subset mytable so that cond2 equals myCond2
myTable = subset(myTable,cond2 == myCond2)
i = c(3,4,5)
myTable[,i] = apply(myTable[,i],2, function(x) as.numeric(as.character(x)))
rm(table1,table2)
effectSize = rank_biserial(myTable$repl,myTable$noRepl, paired = TRUE) %>% interpret(., rules = "funder2019")
pvalue = wilcox.test(myTable$repl,myTable$noRepl, paired = TRUE) %>% .$p.value
pd = data.frame(replacement = myTable$repl, noreplacement = myTable$noRepl)
numOfParticipants = dim(pd)[1]
if (dist_type == "bray"){
colnames(pd) = c("balanced variation in abundance","abundance gradients")
myGraph = ggpubr::ggpaired(pd, cond1 = "balanced variation in abundance", cond2 = "abundance gradients", fill = "condition", palette = "jco", line.size=0.01,
title= (paste(dist_type, "breakdown \n",myCond1,"and",myCond2, "\n Pvalue <",formatC(pvalue, format = "e", digits = 2))),
subtitle = paste0("n =",numOfParticipants,
". Wilcoxon signed rank sum test, P-value < ", formatC(pvalue, format = "e", digits = 5)),
". Rank biserial effect size= ",formatC(effectSize$r_rank_biserial, format = "g", digits = 2)
)} else {
colnames(pd) = c("Turn-over","Nestedness")
myGraph = ggpubr::ggpaired(pd, cond1 = "Turn-over", cond2 = "Nestedness", fill = "condition", palette = "jco", line.size=0.01,
title= (paste(dist_type, "breakdown\n",myCond1,"and",myCond2)),
subtitle = paste0("n =",numOfParticipants,
"\nWilcoxon signed rank sum test, P-value < ",formatC(pvalue, format = "e", digits = 5),
". Rank biserial effect size= ",formatC(effectSize$r_rank_biserial, format = "g", digits = 2))
)}
ggsave(filename=paste0(output,"/",myCond1,"_",myCond2,".svg"),plot=myGraph)
}
?wilcox.test()
for (myConds in comboUniq) {
myCond1 = myConds[1]
myCond2 = myConds[2]
table1 = subset(distance,cond1 == myCond1)
table1 = data.frame(table1$v1,table1$v2,table1[,3],table1$repl,table1$noRepl,table1$cond1,table1$cond2) # Rearrange the columns
colnames(table1) = c("v1","v2",dist_type,"repl","noRepl","cond1","cond2") # Fix the names of the columns
table2 = subset(distance,cond2 == myCond1)
colnames(table2) = c("v1","v2",dist_type,"repl","noRepl","cond2","cond1") # This makes table2 to have the same format as table1
table2 = data.frame(table2$v1,table2$v2,table2[,3],table2$repl,table2$noRepl,table2$cond1,table2$cond2) # Rearrange the columns
colnames(table2) = c("v1","v2",dist_type,"repl","noRepl","cond1","cond2") # Fix the names
myTable = rbind(table1,table2)
# By now myTable cond1 equals myCond1. Next, subset mytable so that cond2 equals myCond2
myTable = subset(myTable,cond2 == myCond2)
i = c(3,4,5)
myTable[,i] = apply(myTable[,i],2, function(x) as.numeric(as.character(x)))
rm(table1,table2)
effectSize = rank_biserial(myTable$repl,myTable$noRepl, paired = TRUE) %>% interpret(., rules = "funder2019")
pvalue = wilcox.test(myTable$repl,myTable$noRepl, paired = TRUE, exact = FALSE) %>% .$p.value
pd = data.frame(replacement = myTable$repl, noreplacement = myTable$noRepl)
numOfParticipants = dim(pd)[1]
if (dist_type == "bray"){
colnames(pd) = c("balanced variation in abundance","abundance gradients")
myGraph = ggpubr::ggpaired(pd, cond1 = "balanced variation in abundance", cond2 = "abundance gradients", fill = "condition", palette = "jco", line.size=0.01,
title= (paste(dist_type, "breakdown \n",myCond1,"and",myCond2, "\n Pvalue <",formatC(pvalue, format = "e", digits = 2))),
subtitle = paste0("n =",numOfParticipants,
". Wilcoxon signed rank sum test, P-value < ", formatC(pvalue, format = "e", digits = 5)),
". Rank biserial effect size= ",formatC(effectSize$r_rank_biserial, format = "g", digits = 2)
)} else {
colnames(pd) = c("Turn-over","Nestedness")
myGraph = ggpubr::ggpaired(pd, cond1 = "Turn-over", cond2 = "Nestedness", fill = "condition", palette = "jco", line.size=0.01,
title= (paste(dist_type, "breakdown\n",myCond1,"and",myCond2)),
subtitle = paste0("n =",numOfParticipants,
"\nWilcoxon signed rank sum test, P-value < ",formatC(pvalue, format = "e", digits = 5),
". Rank biserial effect size= ",formatC(effectSize$r_rank_biserial, format = "g", digits = 2))
)}
ggsave(filename=paste0(output,"/",myCond1,"_",myCond2,".svg"),plot=myGraph)
}
?rank_biserial
