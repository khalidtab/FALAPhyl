}
myGraph
opt = NULL
opt$input = "/Users/khaled/Documents/GitHub/FALAPhyl/data/plots/betapart_bray_pairwise/Tongue_dorsum–Hard_palate.tsv"
opt$distance = "bray"
opt$category = "condition"
cond = opt$category
dist_type = opt$distance
# Load table
dist = opt$input %>% read_tsv(.,progress = FALSE)
#!/usr/local/bin/Rscript --vanilla
set.seed(1234)
suppressWarnings(suppressMessages(library(dplyr)))
suppressWarnings(suppressMessages(require(tidyverse)))
suppressWarnings(suppressMessages(library(optparse)))
suppressWarnings(suppressMessages(library(ggpubr)))
suppressWarnings(suppressMessages(library(coin)))
cond = opt$category
dist_type = opt$distance
# Load table
dist = opt$input %>% read_tsv(.,progress = FALSE)
currentConds = basename(opt$input) %>% str_split(.,".tsv")%>% .[[1]] %>% .[1] %>% str_split(.,"–")
myCond1 = currentConds[[1]][1]
myCond2 = currentConds[[1]][2]
opt$mapping = "/Users/khaled/Documents/GitHub/FALAPhyl/data/map/v35_oral_gs.txt"
map = opt$mapping
map = suppressMessages(read_tsv(map))
opt$output = "/Users/khaled/Documents/GitHub/FALAPhyl/data/plots/test.svg"
output = opt$output
column1 = dist[,1] %>% as.data.frame(.) %>% .[,1] %>% as.numeric(.)
column2 = dist[,2] %>% as.data.frame(.) %>% .[,1] %>% as.numeric(.)
pvalue = wilcox.test(column1,column2, paired = TRUE) %>% .$p.value
install.packages("effectsize")
suppressWarnings(suppressMessages(library(effectsize)))
?effectsize
View(dist)
dist2 = cbind(rownames(dist),dist)
View(dist2)
colnames(dist2)[1] = "SampleID"
?pivot_longer()
dist3 = pivot_longer(data)
dist3 = pivot_longer(data,cols=c("SampleID"))
vignette("pivot")
dist3 = dist2 %>% pivot_longer(!SampleID,names_to = "type",values_to="value")
View(dist3)
?kendalls_w
kendalls_w(y~type|SampleID,data = dist3)
kendalls_w(value~type|SampleID,data = dist3)
kendalls_w(value~type|SampleID,data = dist3, verbose = TRUE)
kendalls_w(value~type|SampleID,data = dist3, verbose = TRUE, paired = TRUE)
kendalls_w(value~type|SampleID,data = dist3, verbose = TRUE, paired = TRUE)
hi = kendalls_w(value~type|SampleID,data = dist3, verbose = TRUE, paired = TRUE
)
interpret(hi)
interpret(hi, rules=“funder2019)
interpret(hi, rules=”funder2019”)
interpret(hi, rules="funder2019")
?interpret
hi$Kendalls_W
interpret_kendalls_w(hi$Kendalls_W)
interpret_kendalls_w(hi$Kendalls_W,rules="funder2019")
interpret_kendalls_w(hi$Kendalls_W,rules)
interpret_kendalls_w(hi$Kendalls_W)
hi$Kendalls_W
hi = rank_biserial(value~type|SampleID,data = dist3, verbose = TRUE, paired = TRUE)
hi = rank_biserial(column1,column2, paired = TRUE)
hi
interpret(hi, rules = "funder2019")
hi = rank_biserial(column1,column2, paired = TRUE) %>% interpret(., rules = "funder2019")
hi$r_rank_biserial
hi$Interpretation
pvalue = wilcox.test(column1,column2, paired = TRUE) %>% .$p.value
pvalue
effectSize = rank_biserial(column1,column2, paired = TRUE) %>% interpret(., rules = "funder2019")
effectSize$r_rank_biserial
myGraph = ggpubr::ggpaired(dist, cond1 = "balanced variation in abundance", cond2 = "abundance gradients", fill = "condition", palette = "jco", line.size=0.01, title= (paste0(dist_type, " breakdown \nbetween ",myCond1,"and",myCond2, "\np-value <",formatC(pvalue, format = "e", digits = 2, ". Rank biserial effect size= ",effectSize$r_rank_biserial))))
myGraph = ggpubr::ggpaired(dist, cond1 = "balanced variation in abundance", cond2 = "abundance gradients", fill = "condition", palette = "jco", line.size=0.01,
title= (paste0(dist_type, " breakdown \nbetween ",myCond1,"and",myCond2, "\np-value <",formatC(pvalue, format = "e", digits = 2), ". Rank biserial effect size= ",effectSize$r_rank_biserial)))
myGraph
myGraph = ggpubr::ggpaired(dist, cond1 = "balanced variation in abundance", cond2 = "abundance gradients", fill = "condition", palette = "jco", line.size=0.01,
title= (paste0(dist_type, " breakdown \nbetween ",myCond1,"and",myCond2, "\np-value <",formatC(pvalue, format = "e", digits = 2), ". Rank biserial effect size= ",formatC(effectSize$r_rank_biserial, format = "e", digits = 2))))
myGraph
?formatC()
myGraph = ggpubr::ggpaired(dist, cond1 = "balanced variation in abundance", cond2 = "abundance gradients", fill = "condition", palette = "jco", line.size=0.01,
title= (paste0(dist_type, " breakdown \nbetween ",myCond1,"and",myCond2, "\np-value <",formatC(pvalue, format = "g", digits = 2), ". Rank biserial effect size= ",formatC(effectSize$r_rank_biserial, format = "g", digits = 2))))
formatC(effectSize$r_rank_biserial, format = "g", digits = 2)
myGraph = ggpubr::ggpaired(dist, cond1 = "balanced variation in abundance", cond2 = "abundance gradients", fill = "condition", palette = "jco", line.size=0.01,
title= (paste0(dist_type, " breakdown \nbetween ",myCond1," and ",myCond2, "\np-value <",formatC(pvalue, format = "g", digits = 2), ". Rank biserial effect size= ",formatC(effectSize$r_rank_biserial, format = "g", digits = 2))))
myGraph = ggpubr::ggpaired(dist, cond1 = "balanced variation in abundance", cond2 = "abundance gradients", fill = "condition", palette = "jco", line.size=0.01,
title= (paste0(dist_type, " breakdown \nbetween ",myCond1," and ",myCond2, "\np-value <",formatC(pvalue, format = "g", digits = 2), ". Rank biserial effect size= ",formatC(effectSize$r_rank_biserial, format = "g", digits = 2))))
myGraph
myGraph = ggpubr::ggpaired(dist, cond1 = "balanced variation in abundance", cond2 = "abundance gradients", fill = "condition", palette = "jco", line.size=0.01,
title= (paste0(dist_type, " breakdown \nbetween ",myCond1," and ",myCond2)), subtitle("\np-value <",formatC(pvalue, format = "g", digits = 2), ". Rank biserial effect size= ",formatC(effectSize$r_rank_biserial, format = "g", digits = 2)))
myGraph = ggpubr::ggpaired(dist, cond1 = "balanced variation in abundance", cond2 = "abundance gradients", fill = "condition", palette = "jco", line.size=0.01,
title= (paste0(dist_type, " breakdown \nbetween ",myCond1," and ",myCond2, "\np-value <",formatC(pvalue, format = "g", digits = 2), ". Rank biserial effect size= ",formatC(effectSize$r_rank_biserial, format = "g", digits = 2))))
?ggpaired()
myGraph = ggpubr::ggpaired(dist, cond1 = "balanced variation in abundance", cond2 = "abundance gradients", fill = "condition", palette = "jco", line.size=0.01,
title= (paste0(dist_type, " breakdown \nbetween ",myCond1," and ",myCond2, "\np-value <",formatC(pvalue, format = "g", digits = 2), ". Rank biserial effect size= ",formatC(effectSize$r_rank_biserial, format = "g", digits = 2))))
myGraph
if (pvalue == 0){
pvalue = 0.01
}
pvalue
if (pvalue == 0){
pvalue = 0.001
}
pvalue
pvalue=0
if (pvalue == 0){
pvalue = 0.001
}
pvalue
if (dist_type == "bray"){
myGraph = ggpubr::ggpaired(dist, cond1 = "balanced variation in abundance", cond2 = "abundance gradients", fill = "condition", palette = "jco", line.size=0.01,
title= (paste0(dist_type, " breakdown \nbetween ",myCond1," and ",myCond2, "\np-value <",formatC(pvalue, format = "g", digits = 2), ". Rank biserial effect size= ",formatC(effectSize$r_rank_biserial, format = "g", digits = 2))))
} else {
myGraph = ggpubr::ggpaired(dist, cond1 = "Turn-over", cond2 = "Nestedness", fill = "condition", palette = "jco", line.size=0.01,
title= (paste0(dist_type, " breakdown \nbetween ",myCond1," and ",myCond2, "\np-value <",formatC(pvalue, format = "g", digits = 2), ". Rank biserial effect size= ",formatC(effectSize$r_rank_biserial, format = "g", digits = 2))))
}
myGraph
bquote(X-Axis[subscript])
#!/usr/local/bin/Rscript --vanilla
set.seed(1234)
suppressWarnings(suppressMessages(library(dplyr)))
suppressWarnings(suppressMessages(require(tidyverse)))
suppressWarnings(suppressMessages(library(optparse)))
suppressWarnings(suppressMessages(library(ggpubr)))
suppressWarnings(suppressMessages(library(effectsize)))
opt = NULL
opt$category = "condition"
opt$distance = "bray"
opt$input = "/Users/khaled/Documents/GitHub/FALAPhyl/data/plots/betapart_bray_pairwise/Tongue_dorsum–Hard_palate.tsv"
cond = opt$category
dist_type = opt$distance
# Load table
dist = opt$input %>% read_tsv(.,progress = FALSE)
currentConds = basename(opt$input) %>% str_split(.,".tsv")%>% .[[1]] %>% .[1] %>% str_split(.,"–")
myCond1 = currentConds[[1]][1]
myCond2 = currentConds[[1]][2]
opt$mapping = "/Users/khaled/Documents/GitHub/FALAPhyl/data/map/v35_oral_gs.txt"
map = suppressMessages(read_tsv(map))
map = opt$mapping
map = suppressMessages(read_tsv(map))
opt$output = "/Users/khaled/Documents/GitHub/FALAPhyl/data/plots/test.svg"
output = opt$output
column1 = dist[,1] %>% as.data.frame(.) %>% .[,1] %>% as.numeric(.)
column2 = dist[,2] %>% as.data.frame(.) %>% .[,1] %>% as.numeric(.)
dist2 = cbind(rownames(dist),dist)
colnames(dist2)[1] = "SampleID"
dist3 = dist2 %>% pivot_longer(!SampleID,names_to = "type",values_to="value")
effectSize = rank_biserial(column1,column2, paired = TRUE) %>% interpret(., rules = "funder2019")
pvalue = wilcox.test(column1,column2, paired = TRUE) %>% .$p.value
effectSize
myGraph = ggpubr::ggpaired(dist, cond1 = "balanced variation in abundance", cond2 = "abundance gradients", fill = "condition", palette = "jco", line.size=0.01,
title= (paste0(dist_type, " breakdown \nbetween ",myCond1," and ",myCond2, "\np-value <",formatC(pvalue, format = "g", digits = 2),  bquote(R[rank by serial]),"= ",formatC(effectSize$r_rank_biserial, format = "g", digits = 2))))
effectSize
myGraph = ggpubr::ggpaired(dist, cond1 = "balanced variation in abundance", cond2 = "abundance gradients", fill = "condition", palette = "jco", line.size=0.01,
title= (paste0(dist_type, " breakdown \nbetween ",myCond1," and ",myCond2, "\np-value <",formatC(pvalue, format = "g", digits = 2),  bquote(r["rank biserial"]),"= ",formatC(effectSize$r_rank_biserial, format = "g", digits = 2))))
myGraph
myGraph = ggpubr::ggpaired(dist, cond1 = "balanced variation in abundance", cond2 = "abundance gradients", fill = "condition", palette = "jco", line.size=0.01,
title= (paste0(dist_type, " breakdown \nbetween ",myCond1," and ",myCond2, "\np-value <",formatC(pvalue, format = "g", digits = 2),  ", Rank biserial effect size=",formatC(effectSize$r_rank_biserial, format = "g", digits = 2))))
myGraph
if (pvalue == 0){ # R sets the pvalue to zero if it is below a certain level, so put it as at least 0.001 if it is too low
pvalue = 0.0001
}
if (dist_type == "bray"){
myGraph = ggpubr::ggpaired(dist, cond1 = "balanced variation in abundance", cond2 = "abundance gradients", fill = "condition", palette = "jco", line.size=0.01,
title= (paste0(dist_type, " breakdown \nbetween ",myCond1," and ",myCond2, "\np-value <",formatC(pvalue, format = "g", digits = 2),  ", Rank biserial effect size=",formatC(effectSize$r_rank_biserial, format = "g", digits = 2))))
} else {
myGraph = ggpubr::ggpaired(dist, cond1 = "Turn-over", cond2 = "Nestedness", fill = "condition", palette = "jco", line.size=0.01,
title= (paste0(dist_type, " breakdown \nbetween ",myCond1," and ",myCond2, "\np-value <",formatC(pvalue, format = "g", digits = 2),". Rank biserial effect size= ",formatC(effectSize$r_rank_biserial, format = "g", digits = 2))))
}
myGraph
getwd()
print(getwd())
?ggsave
?plot()
?betadisper
# matrix to pairwise
library("optparse")
#library(reshape2)
suppressWarnings(suppressMessages(library(tidyverse)))
suppressWarnings(suppressMessages(library(igraph)))
opt = NULL
opt$input = "/Users/khaled/Documents/GitHub/FALAPhyl/data/network/Attached_Keratinized_gingiva.tsv"
opt$pvalue = "/Users/khaled/Documents/GitHub/FALAPhyl/data/network/pvalue–Attached_Keratinized_gingiva.tsv"
opt$threshold = 0.5
input = opt$input
pvalue = opt$pvalue
threshold = opt$threshold
threshold = as.numeric(threshold)
pvaluethreshold = opt$pvaluethreshold
pvaluethreshold = as.numeric(pvaluethreshold)
# Unpack/Melt the correlation matrix table
myInput = suppressMessages(read_tsv(input))
myInput =  as.data.frame(myInput)
row.names(myInput) = myInput[,1]
myInput$`#OTU ID` = NULL # by now, row names and column names are the feature ID
myInput = as.matrix(myInput)
myInput = replace(myInput, lower.tri(myInput, TRUE), NA)
myInput = reshape2::melt(myInput, na.rm = TRUE)
colnames(myInput) = c("Source","Target","corrWeight")
# Unpack/Melt the pvalue matrix table
mypvalue = suppressMessages(read_tsv(pvalue))
mypvalue =  as.data.frame(mypvalue)
row.names(mypvalue) = mypvalue[,1]
mypvalue$`#OTU ID` = NULL # by now, row names and column names are the feature ID
mypvalue = as.matrix(mypvalue)
mypvalue = replace(mypvalue, lower.tri(mypvalue, TRUE), NA)
mypvalue = reshape2::melt(mypvalue, na.rm = TRUE)
colnames(mypvalue) = c("Source","Target","pvalue")
myTable = merge(myInput,mypvalue)
Type = rep("Undirected", length(rownames(myTable)))
myTable = cbind(myTable,Type)
myTable = cbind(myTable, abs(myTable$corrWeight))
myTable = subset(myTable, abs(myTable$corrWeight) >= threshold) # Subset to only correlations that fit the criteria
myTable$`abs(myTable$corrWeight)` = NULL
myTable = subset(myTable, abs(myTable$pvalue) < pvaluethreshold) # Subset to only pvalues less than the pvalue threshold
weight = myTable$corrWeight
myTable = cbind(myTable,weight)
myTable$weight[myTable$weight < 0] = 0 # This way, the louvain modularity function below will not consider negative correlations between two edges as a positive correlation and be influenced to place them in the same cluster
row.names(myTable) = NULL # At this point, you have a pairwise table that was filtered to the level specified
tableForModularity = myTable
tableForModularity = subset(tableForModularity, tableForModularity$weight != 0) # Subset to only correlations that are positive
tableForModularity = subset(tableForModularity, tableForModularity$Source != "Others") # Remove others so it doesn't mess up the Louvain algorithm
View(tableForModularity)
# Unpack/Melt the correlation matrix table
myInput = suppressMessages(read_tsv(input))
myInput =  as.data.frame(myInput)
row.names(myInput) = myInput[,1]
myInput$`#OTU ID` = NULL # by now, row names and column names are the feature ID
myInput = as.matrix(myInput)
myInput = replace(myInput, lower.tri(myInput, TRUE), NA)
myInput = reshape2::melt(myInput, na.rm = TRUE)
colnames(myInput) = c("Source","Target","corrWeight")
# Unpack/Melt the pvalue matrix table
mypvalue = suppressMessages(read_tsv(pvalue))
mypvalue =  as.data.frame(mypvalue)
row.names(mypvalue) = mypvalue[,1]
mypvalue$`#OTU ID` = NULL # by now, row names and column names are the feature ID
mypvalue = as.matrix(mypvalue)
mypvalue = replace(mypvalue, lower.tri(mypvalue, TRUE), NA)
mypvalue = reshape2::melt(mypvalue, na.rm = TRUE)
colnames(mypvalue) = c("Source","Target","pvalue")
myTable = merge(myInput,mypvalue)
Type = rep("Undirected", length(rownames(myTable)))
myTable = cbind(myTable,Type)
myTable = cbind(myTable, abs(myTable$corrWeight))
myTable = subset(myTable, abs(myTable$corrWeight) >= threshold) # Subset to only correlations that fit the criteria
myTable$`abs(myTable$corrWeight)` = NULL
View(myTable)
myInput = suppressMessages(read_tsv(input))
myInput =  as.data.frame(myInput)
row.names(myInput) = myInput[,1]
myInput$`#OTU ID` = NULL # by now, row names and column names are the feature ID
myInput = as.matrix(myInput)
myInput = replace(myInput, lower.tri(myInput, TRUE), NA)
myInput = reshape2::melt(myInput, na.rm = TRUE)
colnames(myInput) = c("Source","Target","corrWeight")
# Unpack/Melt the pvalue matrix table
mypvalue = suppressMessages(read_tsv(pvalue))
mypvalue =  as.data.frame(mypvalue)
row.names(mypvalue) = mypvalue[,1]
mypvalue$`#OTU ID` = NULL # by now, row names and column names are the feature ID
mypvalue = as.matrix(mypvalue)
mypvalue = replace(mypvalue, lower.tri(mypvalue, TRUE), NA)
mypvalue = reshape2::melt(mypvalue, na.rm = TRUE)
colnames(mypvalue) = c("Source","Target","pvalue")
myTable = merge(myInput,mypvalue)
Type = rep("Undirected", length(rownames(myTable)))
myTable = cbind(myTable,Type)
View(myTable)
myTable = cbind(myTable, abs(myTable$corrWeight))
myTable = subset(myTable, abs(myTable$corrWeight) >= threshold) # Subset to only correlations that fit the criteria
myTable$`abs(myTable$corrWeight)` = NULL
pvaluethreshold
pvaluethreshold = 0.05
myTable = subset(myTable, abs(myTable$pvalue) < pvaluethreshold)
weight = myTable$corrWeight
myTable = cbind(myTable,weight)
myTable$weight[myTable$weight < 0] = 0 # This way, the louvain modularity function below will not consider negative correlations between two edges as a positive correlation and be influenced to place them in the same cluster
row.names(myTable) = NULL # At this point, you have a pairwise table that was filtered to the level specified
tableForModularity = myTable
tableForModularity = subset(tableForModularity, tableForModularity$weight != 0) # Subset to only correlations that are positive
View(tableForModularity)
tableForModularity = subset(tableForModularity, tableForModularity$Source != "Others") # Remove others so it doesn't mess up the Louvain algorithm
View(tableForModularity)
myigraph = graph.data.frame(tableForModularity, directed = FALSE)
myModularity = cluster_louvain(myigraph) #Same method as Gephi
nodesList = cbind(myModularity$names,myModularity$membership)
colnames(nodesList) = c("Id","Community")
nodesList = as.data.frame(nodesList)
# To make it easier to do the Zi-Pi calculations for each OTU, copy myTable to another, and append it with the "Target" OTU being the "Source"
myTable$weight = NULL
newTable = myTable
colnames(newTable) = c("Target","Source","corrWeight","pvalue","Type")
newTable = cbind(newTable$Source,newTable$Target,
newTable$corrWeight,newTable$pvalue,
as.character(newTable$Type))
colnames(newTable) = c("Source","Target","corrWeight","pvalue","Type")
newTable = as.data.frame(newTable, stringsAsFactors=FALSE)
myTable2 = rbind(newTable,myTable)
View(myTable2)
#Combine nodesList to the myTable2 to make it easier subset the table
Source = nodesList %>% as.data.frame()
colnames(Source) = c("Source","SourceCommunity")
myTable2 = merge(myTable2,Source)
Target = nodesList %>% as.data.frame()
colnames(Target) = c("Target","TargetCommunity")
myTable2 = merge(myTable2,Target)
colnames(myTable2) = c("Target","Source","Weight","pvalue",
"Type","SourceCommunity","TargetCommunity")
myTable = myTable2
View(newTable)
rm(myTable2,Source, Target, newTable,myigraph,
Type,mypvalue,myInput,weight,input,pvalue)
zipiTable = matrix(NA, ncol = 3, nrow = length(nodesList$Id)) %>% as.data.frame(.,stringsAsFactors=FALSE)
colnames(zipiTable) = c("Id","Zi","Pi")
zipiTable$Id = nodesList$Id
View(zipiTable)
myCommunities = unique(myTable$SourceCommunity) %>% as.character(.)
#Zi calculations
for (x in (1:length(myCommunities))){
## Leave only edges coming from nodes in the same community
myComm = myCommunities[x] %>% as.character(.)
currentComm = subset(myTable, SourceCommunity==myComm)
currentComm = subset(currentComm, TargetCommunity==myComm)
if (dim(currentComm)[1] == 0){next} #Break out if the current Community has only negative edges to other nodes, or if the node doesn't have any edges to nodes within the same community. These communities don't get reported through this method.
uniq_comm_ids = c(unique(currentComm$Source),unique(currentComm$Target))
comm_zi = matrix(NA, ncol = 7, nrow = length(uniq_comm_ids)) %>% as.data.frame(.,stringsAsFactors=FALSE)
colnames(comm_zi) = c("Id","NumOfSourceConnections","NumOfTargetConnections","NumOfConnections","average","STDev","Zi")
comm_zi$Id = uniq_comm_ids
for (xx in uniq_comm_ids){ # For source
myNum = subset(currentComm, Source==xx)
myNum = dim(myNum)
myNum = myNum[1]
comm_zi = within(comm_zi, NumOfSourceConnections[Id == xx] <- myNum)
}
for (xx in uniq_comm_ids){ # For target
myNum = subset(currentComm, Target==xx)
myNum = dim(myNum)
myNum = myNum[1]
comm_zi = within(comm_zi, NumOfTargetConnections[Id == xx] <- myNum)
}
comm_zi$NumOfConnections = comm_zi$NumOfSourceConnections + comm_zi$NumOfTargetConnections
comm_zi$NumOfSourceConnections = NULL
comm_zi$NumOfTargetConnections = NULL
comm_zi_STDEV = sd(comm_zi$NumOfConnections)
myCommunities = unique(myTable$SourceCommunity) %>% as.character(.)
#Zi calculations
for (x in (1:length(myCommunities))){
## Leave only edges coming from nodes in the same community
myComm = myCommunities[x] %>% as.character(.)
currentComm = subset(myTable, SourceCommunity==myComm)
currentComm = subset(currentComm, TargetCommunity==myComm)
if (dim(currentComm)[1] == 0){next} #Break out if the current Community has only negative edges to other nodes, or if the node doesn't have any edges to nodes within the same community. These communities don't get reported through this method.
uniq_comm_ids = c(unique(currentComm$Source),unique(currentComm$Target))
comm_zi = matrix(NA, ncol = 7, nrow = length(uniq_comm_ids)) %>% as.data.frame(.,stringsAsFactors=FALSE)
colnames(comm_zi) = c("Id","NumOfSourceConnections","NumOfTargetConnections","NumOfConnections","average","STDev","Zi")
comm_zi$Id = uniq_comm_ids
for (xx in uniq_comm_ids){ # For source
myNum = subset(currentComm, Source==xx)
myNum = dim(myNum)
myNum = myNum[1]
comm_zi = within(comm_zi, NumOfSourceConnections[Id == xx] <- myNum)
}
for (xx in uniq_comm_ids){ # For target
myNum = subset(currentComm, Target==xx)
myNum = dim(myNum)
myNum = myNum[1]
comm_zi = within(comm_zi, NumOfTargetConnections[Id == xx] <- myNum)
}
comm_zi$NumOfConnections = comm_zi$NumOfSourceConnections + comm_zi$NumOfTargetConnections
comm_zi$NumOfSourceConnections = NULL
comm_zi$NumOfTargetConnections = NULL
comm_zi_STDEV = sd(comm_zi$NumOfConnections)
if (is.na(comm_zi_STDEV) == TRUE){
comm_zi$Zi = 0 # Divide by zero is not allowed, therefore we are assigning it as zero instead.
} else if(comm_zi_STDEV == 0) {
comm_zi$Zi = 0 # Divide by zero is not allowed, therefore we are assigning it as zero instead.
} else {
comm_zi$STDev = comm_zi_STDEV
comm_zi$average = ave(comm_zi$NumOfConnections)
comm_zi$Zi = (comm_zi$NumOfConnections - comm_zi$average)/comm_zi$STDev
}
)
for (x in (1:length(myCommunities))){
## Leave only edges coming from nodes in the same community
myComm = myCommunities[x] %>% as.character(.)
currentComm = subset(myTable, SourceCommunity==myComm)
currentComm = subset(currentComm, TargetCommunity==myComm)
if (dim(currentComm)[1] == 0){next} #Break out if the current Community has only negative edges to other nodes, or if the node doesn't have any edges to nodes within the same community. These communities don't get reported through this method.
uniq_comm_ids = c(unique(currentComm$Source),unique(currentComm$Target))
comm_zi = matrix(NA, ncol = 7, nrow = length(uniq_comm_ids)) %>% as.data.frame(.,stringsAsFactors=FALSE)
colnames(comm_zi) = c("Id","NumOfSourceConnections","NumOfTargetConnections","NumOfConnections","average","STDev","Zi")
comm_zi$Id = uniq_comm_ids
for (xx in uniq_comm_ids){ # For source
myNum = subset(currentComm, Source==xx)
myNum = dim(myNum)
myNum = myNum[1]
comm_zi = within(comm_zi, NumOfSourceConnections[Id == xx] <- myNum)
}
for (xx in uniq_comm_ids){ # For target
myNum = subset(currentComm, Target==xx)
myNum = dim(myNum)
myNum = myNum[1]
comm_zi = within(comm_zi, NumOfTargetConnections[Id == xx] <- myNum)
}
comm_zi$NumOfConnections = comm_zi$NumOfSourceConnections + comm_zi$NumOfTargetConnections
comm_zi$NumOfSourceConnections = NULL
comm_zi$NumOfTargetConnections = NULL
comm_zi_STDEV = sd(comm_zi$NumOfConnections)
if (is.na(comm_zi_STDEV) == TRUE){
comm_zi$Zi = 0 # Divide by zero is not allowed, therefore we are assigning it as zero instead.
} else if(comm_zi_STDEV == 0) {
comm_zi$Zi = 0 # Divide by zero is not allowed, therefore we are assigning it as zero instead.
} else {
comm_zi$STDev = comm_zi_STDEV
comm_zi$average = ave(comm_zi$NumOfConnections)
comm_zi$Zi = (comm_zi$NumOfConnections - comm_zi$average)/comm_zi$STDev
}
comm_zi$NumOfConnections = NULL
comm_zi$average = NULL
comm_zi$STDev = NULL
zipiTable = merge(zipiTable,comm_zi, by="Id", all.x = TRUE, all.y = TRUE)
myValues = coalesce(as.double(zipiTable$Zi.y),as.double(zipiTable$Zi.x))
zipiTable$Zi.x = NULL
colnames(zipiTable) = c("Id","Pi","Zi")
zipiTable$Zi = myValues
}
rm(comm_zi,comm_zi_STDEV,currentComm,myComm,myCommunities,myNum,myValues,uniq_comm_ids,x,xx)
View(zipiTable)
zipiTable = unique(zipiTable) # There are some duplicate measurements of the table, so only keep unique ones
for (x in nodesList$Id){
# x = nodesList$Id[2]
piTotalTableSource = subset(myTable, Source==x)
piTotalTableTarget = subset(myTable, Target==x)
colnames(piTotalTableTarget) = c("Source","Target","Weight","pvalue","Type","TargetCommunity","SourceCommunity") # Change the target to a source, including the community
piTotalTable = rbind(piTotalTableSource,piTotalTableTarget)
total = dim(piTotalTable)[1]
sigma = 0
for (y in unique(piTotalTable$TargetCommunity)){
commConnections = subset(piTotalTable, TargetCommunity==y) %>% dim(.) %>% .[1]
fraction = (commConnections/total)^2
sigma = sigma + fraction
}
featurePiScore = 1-sigma
zipiTable = within(zipiTable, Pi[Id == x] <- featurePiScore)
}
zipiTable = merge(zipiTable,nodesList)
rm(x,y,total,sigma,piTotalTable,myModularity,fraction,featurePiScore,nodesList,commConnections)
View(zipiTable)
View(myTable)
opt = NULL
opt$input = zipiTable
opt$threshold = 0.1
opt$pvalue = 0.05
threshold = opt$threshold # threshold = "0.1"
pvalue = opt$pvalue # pvalue = "0.05"
pvalue$core = 0.5
opt$core = 0.5
core = opt$core # core = "0.8"
core = as.numeric(core)
zipiTableLabels = cbind(zipiTable,zipiTable$Id)
colnames(zipiTableLabels) = c("Id","Pi","Zi","Community","Label")
View(zipiTableLabels)
PiLabels = filter(zipiTableLabels,Pi>=0.62)
ZiLabels = filter(zipiTableLabels,Zi>=2.5)
labeledPoints = rbind(PiLabels,ZiLabels)
unlabeledPoints = subset(zipiTableLabels, !(Id %in% labeledPoints$Id))
unlabeledPoints$Label = ""
zipiTableLabels = rbind(unlabeledPoints,labeledPoints)
View(zipiTableLabels)
annotations <- data.frame(
xpos = c(-Inf,-Inf,Inf,Inf),
ypos =  c(-Inf, Inf,-Inf,Inf),
annotateText = c("Peripherals","Module hubs"
,"Connectors","Network hubs"),
hjustvar = c(0,0,1,1) ,
vjustvar = c(0,1,0,1)) #<- adjust
zipiPlot =  ggplot(zipiTableLabels, aes(x = Pi, y = Zi, label = Label)) +
geom_point(color = "dark blue", position = "jitter") + geom_hline(yintercept = 2.5, color = "dark green", size = 1) +
geom_vline(xintercept = 0.62, color = "orange", size = 1) +
labs(x = "Among modules connectivity (Pi)", y = "Within module connectivity (Zi") +
geom_text(data=annotations,aes(x=xpos,y=ypos,hjust=hjustvar,vjust=vjustvar,label=annotateText)) +
geom_label_repel(max.overlaps = 50) +
labs(title = paste0("ZiPi plot. # of nodes = ", length(zipiTable$Id),", Core = " ,(core*100),"%, Threshold = ",threshold, ", p-value < ",pvalue)) +
theme(plot.title = element_text(hjust = 0.5))
gt = ggplot_gtable(ggplot_build(zipiPlot))
gt$layout$clip[gt$layout$name == "panel"] <- "off"
library("optparse")
suppressWarnings(suppressMessages(library("dplyr")))
suppressWarnings(suppressMessages(library(tidyverse)))
suppressWarnings(suppressMessages(library(ggrepel)))
zipiPlot =  ggplot(zipiTableLabels, aes(x = Pi, y = Zi, label = Label)) +
geom_point(color = "dark blue", position = "jitter") + geom_hline(yintercept = 2.5, color = "dark green", size = 1) +
geom_vline(xintercept = 0.62, color = "orange", size = 1) +
labs(x = "Among modules connectivity (Pi)", y = "Within module connectivity (Zi") +
geom_text(data=annotations,aes(x=xpos,y=ypos,hjust=hjustvar,vjust=vjustvar,label=annotateText)) +
geom_label_repel(max.overlaps = 50) +
labs(title = paste0("ZiPi plot. # of nodes = ", length(zipiTable$Id),", Core = " ,(core*100),"%, Threshold = ",threshold, ", p-value < ",pvalue)) +
theme(plot.title = element_text(hjust = 0.5))
gt = ggplot_gtable(ggplot_build(zipiPlot))
gt$layout$clip[gt$layout$name == "panel"] <- "off"
gt
plot(gt)
pvaluethreshold
grid::grid.draw(gt)
grid::grid.draw(gt)
?grid
library(grid)
?library(grid)
